{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data= pd.read_csv(r\"./dataset/titanic.csv\") \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survived: 생존 여부 (0 = 사망, 1 = 생존) \\\n",
    "Pclass: 티켓 클래스 (1 = 1등석, 2 = 2등석, 3 = 3등석) \\\n",
    "Name: 이름 \\\n",
    "Sex: 성별 \\\n",
    "Age: 나이 \\\n",
    "SibSp: 함께 탑승한 자녀 / 배우자 의 수 \\\n",
    "Parch: 함께 탑승한 부모님 / 아이들 의 수 \\\n",
    "Ticket: 티켓 번호 \\\n",
    "Fare: 탑승 요금 \\\n",
    "Cabin: 수하물 번호 \\\n",
    "Embarked: 선착장 (C = Cherbourg, Q = Queenstown, S = Southampton) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Cabin', 'Embarked', 'Name', 'Ticket', 'PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Age\"].fillna(data.groupby(\"Sex\")[\"Age\"].transform(\"mean\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {\"male\": 0, \"female\": 1}\n",
    "data['Sex'] = data['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age  SibSp  Parch     Fare\n",
       "0           0       3    0  22.000000      1      0   7.2500\n",
       "1           1       1    1  38.000000      1      0  71.2833\n",
       "2           1       3    1  26.000000      0      0   7.9250\n",
       "3           1       1    1  35.000000      1      0  53.1000\n",
       "4           0       3    0  35.000000      0      0   8.0500\n",
       "..        ...     ...  ...        ...    ...    ...      ...\n",
       "886         0       2    0  27.000000      0      0  13.0000\n",
       "887         1       1    1  19.000000      0      0  30.0000\n",
       "888         0       3    1  27.915709      1      2  23.4500\n",
       "889         1       1    0  26.000000      0      0  30.0000\n",
       "890         0       3    0  32.000000      0      0   7.7500\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Survived'],axis=1)\n",
    "Y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X,Y,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "Y_train = Y_train.reset_index(drop=True)\n",
    "Y_test = Y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    x = 1/(1+ np.exp(-z))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25116051, 0.90731452, 0.85283848, 0.99548473, 0.59362549,\n",
       "        0.21748177]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.random.rand(1,X_train.shape[1]) # 랜덤으로 theta값 배열 생성 \n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  1 theta값 :  [[0.24159112 0.9067846  0.73568577 0.9932549  0.59227576 0.12722606]]\n",
      "학습 횟수 :  2 theta값 :  [[0.23202413 0.90625499 0.61853469 0.99102584 0.59092717 0.03698845]]\n",
      "학습 횟수 :  3 theta값 :  [[ 0.22248857  0.90572904  0.50142673  0.98881587  0.58961678 -0.05104688]]\n",
      "학습 횟수 :  4 theta값 :  [[ 0.21320202  0.90529152  0.38837013  0.98673086  0.58852639 -0.10092385]]\n",
      "학습 횟수 :  5 theta값 :  [[ 0.20429173  0.90502528  0.28232727  0.98481471  0.58762769 -0.12185996]]\n",
      "학습 횟수 :  6 theta값 :  [[ 0.19587246  0.90492877  0.18623777  0.98308427  0.58684492 -0.11893246]]\n",
      "학습 횟수 :  7 theta값 :  [[ 0.18810992  0.90495837  0.10293919  0.98150027  0.58614671 -0.09858733]]\n",
      "학습 횟수 :  8 theta값 :  [[ 0.18156465  0.90510254  0.04023818  0.98000031  0.58548661 -0.06407715]]\n",
      "학습 횟수 :  9 theta값 :  [[ 1.76534288e-01  9.05279991e-01 -4.69165921e-04  9.78457349e-01\n",
      "   5.84770221e-01 -2.76570351e-02]]\n",
      "학습 횟수 :  10 theta값 :  [[ 0.17269837  0.90540927 -0.02619131  0.97676094  0.58389427 -0.00816434]]\n",
      "학습 횟수 :  11 theta값 :  [[ 1.69769592e-01  9.05548851e-01 -4.09948294e-02  9.75050985e-01\n",
      "   5.82958825e-01  3.94672064e-04]]\n",
      "학습 횟수 :  12 theta값 :  [[ 0.16741461  0.9057318  -0.04865417  0.97337926  0.58202916  0.00398144]]\n",
      "학습 횟수 :  13 theta값 :  [[ 0.16536981  0.90594898 -0.05236856  0.97173821  0.58111385  0.00552534]]\n",
      "학습 횟수 :  14 theta값 :  [[ 0.16347899  0.90618456 -0.0541408   0.97011402  0.58020759  0.0062791 ]]\n",
      "학습 횟수 :  15 theta값 :  [[ 0.16166526  0.90642933 -0.05496696  0.96849856  0.57930623  0.00665942]]\n",
      "학습 횟수 :  16 theta값 :  [[ 0.15989171  0.90667877 -0.05532018  0.9668878   0.57840764  0.00685108]]\n",
      "학습 횟수 :  17 theta값 :  [[ 0.15814011  0.90693063 -0.05543224  0.96527971  0.57751078  0.00694529]]\n",
      "학습 횟수 :  18 theta값 :  [[ 0.15640122  0.9071838  -0.05541994  0.96367328  0.57661509  0.00698882]]\n",
      "학습 횟수 :  19 theta값 :  [[ 0.15467029  0.90743769 -0.05534316  0.96206799  0.57572032  0.00700592]]\n",
      "학습 횟수 :  20 theta값 :  [[ 0.15294486  0.90769201 -0.05523293  0.96046356  0.5748263   0.00700922]]\n",
      "학습 횟수 :  21 theta값 :  [[ 0.15122363  0.90794659 -0.05510537  0.95885986  0.57393299  0.00700535]]\n",
      "학습 횟수 :  22 theta값 :  [[ 0.14950596  0.90820136 -0.0549689   0.9572568   0.57304033  0.00699775]]\n",
      "학습 횟수 :  23 theta값 :  [[ 0.14779149  0.90845628 -0.05482792  0.95565436  0.57214831  0.00698823]]\n",
      "학습 횟수 :  24 theta값 :  [[ 0.14608003  0.90871132 -0.05468471  0.95405252  0.57125692  0.00697772]]\n",
      "학습 횟수 :  25 theta값 :  [[ 0.14437149  0.90896648 -0.05454047  0.95245126  0.57036615  0.00696673]]\n",
      "학습 횟수 :  26 theta값 :  [[ 0.14266584  0.90922174 -0.05439584  0.95085059  0.56947602  0.00695551]]\n",
      "학습 횟수 :  27 theta값 :  [[ 0.14096303  0.90947711 -0.05425114  0.9492505   0.5685865   0.00694419]]\n",
      "학습 횟수 :  28 theta값 :  [[ 0.13926306  0.90973259 -0.05410653  0.947651    0.56769762  0.00693284]]\n",
      "학습 횟수 :  29 theta값 :  [[ 0.13756592  0.90998817 -0.05396211  0.94605208  0.56680936  0.00692151]]\n",
      "학습 횟수 :  30 theta값 :  [[ 0.13587161  0.91024385 -0.05381792  0.94445375  0.56592173  0.0069102 ]]\n",
      "학습 횟수 :  31 theta값 :  [[ 0.13418013  0.91049964 -0.05367398  0.94285601  0.56503474  0.00689893]]\n",
      "학습 횟수 :  32 theta값 :  [[ 0.13249147  0.91075553 -0.05353031  0.94125886  0.56414837  0.00688771]]\n",
      "학습 횟수 :  33 theta값 :  [[ 0.13080565  0.91101153 -0.05338692  0.9396623   0.56326265  0.00687653]]\n",
      "학습 횟수 :  34 theta값 :  [[ 0.12912265  0.91126763 -0.0532438   0.93806634  0.56237756  0.0068654 ]]\n",
      "학습 횟수 :  35 theta값 :  [[ 0.12744249  0.91152385 -0.05310096  0.93647097  0.56149311  0.00685432]]\n",
      "학습 횟수 :  36 theta값 :  [[ 0.12576515  0.91178017 -0.05295841  0.93487621  0.5606093   0.00684328]]\n",
      "학습 횟수 :  37 theta값 :  [[ 0.12409064  0.9120366  -0.05281613  0.93328205  0.55972613  0.0068323 ]]\n",
      "학습 횟수 :  38 theta값 :  [[ 0.12241897  0.91229313 -0.05267413  0.93168849  0.55884361  0.00682136]]\n",
      "학습 횟수 :  39 theta값 :  [[ 0.12075013  0.91254978 -0.05253241  0.93009554  0.55796174  0.00681047]]\n",
      "학습 횟수 :  40 theta값 :  [[ 0.11908413  0.91280654 -0.05239098  0.92850319  0.55708051  0.00679963]]\n",
      "학습 횟수 :  41 theta값 :  [[ 0.11742096  0.9130634  -0.05224982  0.92691146  0.55619993  0.00678884]]\n",
      "학습 횟수 :  42 theta값 :  [[ 0.11576062  0.91332038 -0.05210894  0.92532034  0.55532001  0.0067781 ]]\n",
      "학습 횟수 :  43 theta값 :  [[ 0.11410312  0.91357747 -0.05196834  0.92372984  0.55444074  0.00676741]]\n",
      "학습 횟수 :  44 theta값 :  [[ 0.11244846  0.91383468 -0.05182802  0.92213995  0.55356213  0.00675676]]\n",
      "학습 횟수 :  45 theta값 :  [[ 0.11079664  0.91409199 -0.05168798  0.92055068  0.55268417  0.00674616]]\n",
      "학습 횟수 :  46 theta값 :  [[ 0.10914765  0.91434942 -0.05154822  0.91896204  0.55180687  0.00673562]]\n",
      "학습 횟수 :  47 theta값 :  [[ 0.10750151  0.91460696 -0.05140874  0.91737401  0.55093024  0.00672512]]\n",
      "학습 횟수 :  48 theta값 :  [[ 0.1058582   0.91486462 -0.05126953  0.91578662  0.55005427  0.00671467]]\n",
      "학습 횟수 :  49 theta값 :  [[ 0.10421773  0.9151224  -0.05113061  0.91419985  0.54917896  0.00670426]]\n",
      "학습 횟수 :  50 theta값 :  [[ 0.10258011  0.91538029 -0.05099196  0.91261371  0.54830432  0.00669391]]\n",
      "학습 횟수 :  51 theta값 :  [[ 0.10094533  0.91563829 -0.05085359  0.9110282   0.54743035  0.0066836 ]]\n",
      "학습 횟수 :  52 theta값 :  [[ 0.09931339  0.91589642 -0.0507155   0.90944333  0.54655705  0.00667334]]\n",
      "학습 횟수 :  53 theta값 :  [[ 0.09768429  0.91615466 -0.05057769  0.9078591   0.54568443  0.00666313]]\n",
      "학습 횟수 :  54 theta값 :  [[ 0.09605804  0.91641302 -0.05044015  0.9062755   0.54481248  0.00665297]]\n",
      "학습 횟수 :  55 theta값 :  [[ 0.09443463  0.9166715  -0.05030289  0.90469255  0.5439412   0.00664285]]\n",
      "학습 횟수 :  56 theta값 :  [[ 0.09281406  0.9169301  -0.05016591  0.90311024  0.54307061  0.00663278]]\n",
      "학습 횟수 :  57 theta값 :  [[ 0.09119635  0.91718882 -0.0500292   0.90152858  0.54220069  0.00662276]]\n",
      "학습 횟수 :  58 theta값 :  [[ 0.08958147  0.91744766 -0.04989278  0.89994756  0.54133145  0.00661279]]\n",
      "학습 횟수 :  59 theta값 :  [[ 0.08796945  0.91770662 -0.04975663  0.8983672   0.5404629   0.00660287]]\n",
      "학습 횟수 :  60 theta값 :  [[ 0.08636027  0.9179657  -0.04962075  0.89678748  0.53959504  0.00659299]]\n",
      "학습 횟수 :  61 theta값 :  [[ 0.08475394  0.9182249  -0.04948515  0.89520843  0.53872786  0.00658316]]\n",
      "학습 횟수 :  62 theta값 :  [[ 0.08315046  0.91848423 -0.04934983  0.89363003  0.53786137  0.00657338]]\n",
      "학습 횟수 :  63 theta값 :  [[ 0.08154983  0.91874369 -0.04921478  0.89205229  0.53699557  0.00656364]]\n",
      "학습 횟수 :  64 theta값 :  [[ 0.07995204  0.91900326 -0.04908001  0.89047521  0.53613047  0.00655396]]\n",
      "학습 횟수 :  65 theta값 :  [[ 0.07835711  0.91926296 -0.04894552  0.88889879  0.53526606  0.00654432]]\n",
      "학습 횟수 :  66 theta값 :  [[ 0.07676502  0.91952279 -0.0488113   0.88732304  0.53440235  0.00653473]]\n",
      "학습 횟수 :  67 theta값 :  [[ 0.07517579  0.91978274 -0.04867735  0.88574796  0.53353933  0.00652518]]\n",
      "학습 횟수 :  68 theta값 :  [[ 0.07358941  0.92004282 -0.04854368  0.88417355  0.53267702  0.00651568]]\n",
      "학습 횟수 :  69 theta값 :  [[ 0.07200588  0.92030303 -0.04841029  0.88259981  0.53181541  0.00650623]]\n",
      "학습 횟수 :  70 theta값 :  [[ 0.0704252   0.92056336 -0.04827717  0.88102675  0.5309545   0.00649683]]\n",
      "학습 횟수 :  71 theta값 :  [[ 0.06884737  0.92082382 -0.04814432  0.87945436  0.5300943   0.00648747]]\n",
      "학습 횟수 :  72 theta값 :  [[ 0.0672724   0.92108442 -0.04801175  0.87788266  0.5292348   0.00647816]]\n",
      "학습 횟수 :  73 theta값 :  [[ 0.06570028  0.92134514 -0.04787945  0.87631164  0.52837602  0.0064689 ]]\n",
      "학습 횟수 :  74 theta값 :  [[ 0.06413101  0.92160599 -0.04774743  0.8747413   0.52751794  0.00645968]]\n",
      "학습 횟수 :  75 theta값 :  [[ 0.06256459  0.92186697 -0.04761568  0.87317165  0.52666058  0.00645051]]\n",
      "학습 횟수 :  76 theta값 :  [[ 0.06100103  0.92212808 -0.0474842   0.87160268  0.52580394  0.00644139]]\n",
      "학습 횟수 :  77 theta값 :  [[ 0.05944033  0.92238932 -0.047353    0.87003441  0.52494801  0.00643231]]\n",
      "학습 횟수 :  78 theta값 :  [[ 0.05788248  0.9226507  -0.04722207  0.86846683  0.5240928   0.00642328]]\n",
      "학습 횟수 :  79 theta값 :  [[ 0.05632748  0.92291221 -0.04709141  0.86689995  0.52323831  0.0064143 ]]\n",
      "학습 횟수 :  80 theta값 :  [[ 0.05477534  0.92317385 -0.04696103  0.86533377  0.52238454  0.00640537]]\n",
      "학습 횟수 :  81 theta값 :  [[ 0.05322605  0.92343563 -0.04683091  0.86376828  0.52153149  0.00639648]]\n",
      "학습 횟수 :  82 theta값 :  [[ 0.05167962  0.92369754 -0.04670107  0.8622035   0.52067918  0.00638763]]\n",
      "학습 횟수 :  83 theta값 :  [[ 0.05013604  0.92395959 -0.0465715   0.86063943  0.51982758  0.00637883]]\n",
      "학습 횟수 :  84 theta값 :  [[ 0.04859532  0.92422177 -0.04644221  0.85907606  0.51897672  0.00637008]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  85 theta값 :  [[ 0.04705746  0.92448409 -0.04631318  0.8575134   0.51812659  0.00636138]]\n",
      "학습 횟수 :  86 theta값 :  [[ 0.04552245  0.92474654 -0.04618443  0.85595146  0.51727719  0.00635272]]\n",
      "학습 횟수 :  87 theta값 :  [[ 0.0439903   0.92500913 -0.04605595  0.85439022  0.51642853  0.00634411]]\n",
      "학습 횟수 :  88 theta값 :  [[ 0.042461    0.92527186 -0.04592774  0.85282971  0.51558061  0.00633554]]\n",
      "학습 횟수 :  89 theta값 :  [[ 0.04093457  0.92553473 -0.0457998   0.85126991  0.51473342  0.00632702]]\n",
      "학습 횟수 :  90 theta값 :  [[ 0.03941098  0.92579774 -0.04567213  0.84971084  0.51388697  0.00631855]]\n",
      "학습 횟수 :  91 theta값 :  [[ 0.03789026  0.92606089 -0.04554473  0.84815249  0.51304126  0.00631012]]\n",
      "학습 횟수 :  92 theta값 :  [[ 0.03637239  0.92632417 -0.0454176   0.84659487  0.5121963   0.00630174]]\n",
      "학습 횟수 :  93 theta값 :  [[ 0.03485738  0.9265876  -0.04529074  0.84503797  0.51135208  0.0062934 ]]\n",
      "학습 횟수 :  94 theta값 :  [[ 0.03334523  0.92685117 -0.04516415  0.84348181  0.51050861  0.00628511]]\n",
      "학습 횟수 :  95 theta값 :  [[ 0.03183593  0.92711488 -0.04503783  0.84192638  0.50966589  0.00627686]]\n",
      "학습 횟수 :  96 theta값 :  [[ 0.03032949  0.92737873 -0.04491178  0.84037168  0.50882392  0.00626866]]\n",
      "학습 횟수 :  97 theta값 :  [[ 0.02882591  0.92764273 -0.044786    0.83881773  0.5079827   0.00626051]]\n",
      "학습 횟수 :  98 theta값 :  [[ 0.02732519  0.92790686 -0.04466049  0.83726451  0.50714224  0.0062524 ]]\n",
      "학습 횟수 :  99 theta값 :  [[ 0.02582732  0.92817115 -0.04453525  0.83571204  0.50630253  0.00624434]]\n",
      "학습 횟수 :  100 theta값 :  [[ 0.02433231  0.92843557 -0.04441027  0.83416031  0.50546358  0.00623632]]\n",
      "학습 횟수 :  101 theta값 :  [[ 0.02284015  0.92870014 -0.04428557  0.83260933  0.50462539  0.00622835]]\n",
      "학습 횟수 :  102 theta값 :  [[ 0.02135086  0.92896486 -0.04416113  0.8310591   0.50378796  0.00622042]]\n",
      "학습 횟수 :  103 theta값 :  [[ 0.01986442  0.92922972 -0.04403696  0.82950962  0.50295129  0.00621254]]\n",
      "학습 횟수 :  104 theta값 :  [[ 0.01838084  0.92949473 -0.04391306  0.8279609   0.50211539  0.0062047 ]]\n",
      "학습 횟수 :  105 theta값 :  [[ 0.01690011  0.92975989 -0.04378942  0.82641293  0.50128025  0.00619691]]\n",
      "학습 횟수 :  106 theta값 :  [[ 0.01542224  0.93002519 -0.04366605  0.82486573  0.50044589  0.00618917]]\n",
      "학습 횟수 :  107 theta값 :  [[ 0.01394723  0.93029064 -0.04354295  0.82331929  0.49961229  0.00618147]]\n",
      "학습 횟수 :  108 theta값 :  [[ 0.01247508  0.93055624 -0.04342012  0.82177361  0.49877946  0.00617381]]\n",
      "학습 횟수 :  109 theta값 :  [[ 0.01100578  0.93082199 -0.04329756  0.8202287   0.49794741  0.0061662 ]]\n",
      "학습 횟수 :  110 theta값 :  [[ 0.00953934  0.93108789 -0.04317526  0.81868456  0.49711613  0.00615863]]\n",
      "학습 횟수 :  111 theta값 :  [[ 0.00807575  0.93135394 -0.04305322  0.81714119  0.49628563  0.00615111]]\n",
      "학습 횟수 :  112 theta값 :  [[ 0.00661502  0.93162014 -0.04293145  0.81559859  0.49545591  0.00614363]]\n",
      "학습 횟수 :  113 theta값 :  [[ 0.00515714  0.93188649 -0.04280995  0.81405678  0.49462697  0.0061362 ]]\n",
      "학습 횟수 :  114 theta값 :  [[ 0.00370212  0.93215299 -0.04268872  0.81251574  0.49379881  0.00612881]]\n",
      "학습 횟수 :  115 theta값 :  [[ 0.00224996  0.93241964 -0.04256775  0.81097548  0.49297143  0.00612147]]\n",
      "학습 횟수 :  116 theta값 :  [[ 8.00651419e-04  9.32686451e-01 -4.24470398e-02  8.09436009e-01\n",
      "   4.92144839e-01  6.11417316e-03]]\n",
      "학습 횟수 :  117 theta값 :  [[-6.45802617e-04  9.32953411e-01 -4.23265992e-02  8.07897323e-01\n",
      "   4.91319035e-01  6.10691951e-03]]\n",
      "학습 횟수 :  118 theta값 :  [[-0.0020894   0.93322052 -0.04220642  0.80635943  0.49049402  0.00609971]]\n",
      "학습 횟수 :  119 theta값 :  [[-0.00353015  0.93348779 -0.04208651  0.80482232  0.48966979  0.00609255]]\n",
      "학습 횟수 :  120 theta값 :  [[-0.00496804  0.93375521 -0.04196687  0.80328601  0.48884636  0.00608543]]\n",
      "학습 횟수 :  121 theta값 :  [[-0.00640308  0.93402279 -0.04184748  0.8017505   0.48802372  0.00607835]]\n",
      "학습 횟수 :  122 theta값 :  [[-0.00783526  0.93429053 -0.04172836  0.80021579  0.48720188  0.00607132]]\n",
      "학습 횟수 :  123 theta값 :  [[-0.00926459  0.93455841 -0.04160951  0.79868187  0.48638083  0.00606433]]\n",
      "학습 횟수 :  124 theta값 :  [[-0.01069107  0.93482646 -0.04149092  0.79714877  0.48556059  0.00605739]]\n",
      "학습 횟수 :  125 theta값 :  [[-0.01211469  0.93509466 -0.04137259  0.79561646  0.48474114  0.00605049]]\n",
      "학습 횟수 :  126 theta값 :  [[-0.01353547  0.93536302 -0.04125452  0.79408497  0.4839225   0.00604363]]\n",
      "학습 횟수 :  127 theta값 :  [[-0.01495339  0.93563154 -0.04113672  0.79255429  0.48310466  0.00603682]]\n",
      "학습 횟수 :  128 theta값 :  [[-0.01636846  0.93590022 -0.04101918  0.79102443  0.48228762  0.00603005]]\n",
      "학습 횟수 :  129 theta값 :  [[-0.01778068  0.93616906 -0.0409019   0.78949538  0.48147139  0.00602333]]\n",
      "학습 횟수 :  130 theta값 :  [[-0.01919005  0.93643805 -0.04078488  0.78796715  0.48065598  0.00601665]]\n",
      "학습 횟수 :  131 theta값 :  [[-0.02059657  0.93670721 -0.04066813  0.78643974  0.47984137  0.00601001]]\n",
      "학습 횟수 :  132 theta값 :  [[-0.02200024  0.93697652 -0.04055164  0.78491316  0.47902757  0.00600342]]\n",
      "학습 횟수 :  133 theta값 :  [[-0.02340106  0.937246   -0.04043541  0.7833874   0.47821459  0.00599687]]\n",
      "학습 횟수 :  134 theta값 :  [[-0.02479903  0.93751564 -0.04031944  0.78186248  0.47740242  0.00599036]]\n",
      "학습 횟수 :  135 theta값 :  [[-0.02619415  0.93778544 -0.04020373  0.78033838  0.47659107  0.0059839 ]]\n",
      "학습 횟수 :  136 theta값 :  [[-0.02758643  0.9380554  -0.04008828  0.77881512  0.47578054  0.00597748]]\n",
      "학습 횟수 :  137 theta값 :  [[-0.02897585  0.93832553 -0.03997309  0.7772927   0.47497083  0.00597111]]\n",
      "학습 횟수 :  138 theta값 :  [[-0.03036243  0.93859581 -0.03985817  0.77577112  0.47416195  0.00596478]]\n",
      "학습 횟수 :  139 theta값 :  [[-0.03174617  0.93886627 -0.0397435   0.77425038  0.47335388  0.00595849]]\n",
      "학습 횟수 :  140 theta값 :  [[-0.03312706  0.93913688 -0.03962909  0.77273049  0.47254664  0.00595224]]\n",
      "학습 횟수 :  141 theta값 :  [[-0.0345051   0.93940766 -0.03951495  0.77121144  0.47174023  0.00594604]]\n",
      "학습 횟수 :  142 theta값 :  [[-0.0358803   0.93967861 -0.03940106  0.76969325  0.47093465  0.00593988]]\n",
      "학습 횟수 :  143 theta값 :  [[-0.03725265  0.93994972 -0.03928743  0.7681759   0.4701299   0.00593377]]\n",
      "학습 횟수 :  144 theta값 :  [[-0.03862217  0.940221   -0.03917406  0.76665942  0.46932597  0.00592769]]\n",
      "학습 횟수 :  145 theta값 :  [[-0.03998883  0.94049244 -0.03906095  0.76514379  0.46852289  0.00592166]]\n",
      "학습 횟수 :  146 theta값 :  [[-0.04135266  0.94076406 -0.0389481   0.76362902  0.46772063  0.00591568]]\n",
      "학습 횟수 :  147 theta값 :  [[-0.04271364  0.94103583 -0.0388355   0.76211511  0.46691922  0.00590973]]\n",
      "학습 횟수 :  148 theta값 :  [[-0.04407179  0.94130778 -0.03872317  0.76060207  0.46611864  0.00590383]]\n",
      "학습 횟수 :  149 theta값 :  [[-0.04542709  0.94157989 -0.03861109  0.7590899   0.4653189   0.00589797]]\n",
      "학습 횟수 :  150 theta값 :  [[-0.04677955  0.94185218 -0.03849927  0.7575786   0.46452     0.00589216]]\n",
      "학습 횟수 :  151 theta값 :  [[-0.04812917  0.94212463 -0.0383877   0.75606818  0.46372195  0.00588639]]\n",
      "학습 횟수 :  152 theta값 :  [[-0.04947596  0.94239725 -0.0382764   0.75455863  0.46292474  0.00588065]]\n",
      "학습 횟수 :  153 theta값 :  [[-0.05081991  0.94267004 -0.03816535  0.75304996  0.46212838  0.00587497]]\n",
      "학습 횟수 :  154 theta값 :  [[-0.05216102  0.94294301 -0.03805455  0.75154217  0.46133286  0.00586932]]\n",
      "학습 횟수 :  155 theta값 :  [[-0.05349929  0.94321614 -0.03794402  0.75003527  0.46053819  0.00586372]]\n",
      "학습 횟수 :  156 theta값 :  [[-0.05483473  0.94348944 -0.03783374  0.74852926  0.45974438  0.00585816]]\n",
      "학습 횟수 :  157 theta값 :  [[-0.05616733  0.94376292 -0.03772371  0.74702413  0.45895141  0.00585264]]\n",
      "학습 횟수 :  158 theta값 :  [[-0.0574971   0.94403657 -0.03761394  0.7455199   0.4581593   0.00584716]]\n",
      "학습 횟수 :  159 theta값 :  [[-0.05882403  0.94431039 -0.03750443  0.74401656  0.45736805  0.00584173]]\n",
      "학습 횟수 :  160 theta값 :  [[-0.06014814  0.94458438 -0.03739517  0.74251412  0.45657765  0.00583634]]\n",
      "학습 횟수 :  161 theta값 :  [[-0.06146941  0.94485855 -0.03728617  0.74101259  0.45578811  0.00583099]]\n",
      "학습 횟수 :  162 theta값 :  [[-0.06278785  0.94513289 -0.03717742  0.73951195  0.45499944  0.00582568]]\n",
      "학습 횟수 :  163 theta값 :  [[-0.06410345  0.9454074  -0.03706893  0.73801222  0.45421162  0.00582041]]\n",
      "학습 횟수 :  164 theta값 :  [[-0.06541623  0.94568209 -0.03696069  0.7365134   0.45342466  0.00581519]]\n",
      "학습 횟수 :  165 theta값 :  [[-0.06672618  0.94595695 -0.0368527   0.7350155   0.45263858  0.00581001]]\n",
      "학습 횟수 :  166 theta값 :  [[-0.06803331  0.94623199 -0.03674497  0.7335185   0.45185335  0.00580487]]\n",
      "학습 횟수 :  167 theta값 :  [[-0.0693376   0.94650721 -0.0366375   0.73202243  0.451069    0.00579977]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  168 theta값 :  [[-0.07063907  0.9467826  -0.03653027  0.73052727  0.45028551  0.00579471]]\n",
      "학습 횟수 :  169 theta값 :  [[-0.07193771  0.94705816 -0.0364233   0.72903304  0.4495029   0.0057897 ]]\n",
      "학습 횟수 :  170 theta값 :  [[-0.07323353  0.94733391 -0.03631658  0.72753973  0.44872115  0.00578472]]\n",
      "학습 횟수 :  171 theta값 :  [[-0.07452653  0.94760983 -0.03621012  0.72604735  0.44794028  0.00577979]]\n",
      "학습 횟수 :  172 theta값 :  [[-0.0758167   0.94788593 -0.0361039   0.7245559   0.44716029  0.0057749 ]]\n",
      "학습 횟수 :  173 theta값 :  [[-0.07710405  0.94816221 -0.03599794  0.72306539  0.44638117  0.00577005]]\n",
      "학습 횟수 :  174 theta값 :  [[-0.07838858  0.94843866 -0.03589223  0.72157581  0.44560293  0.00576524]]\n",
      "학습 횟수 :  175 theta값 :  [[-0.07967029  0.9487153  -0.03578678  0.72008717  0.44482558  0.00576047]]\n",
      "학습 횟수 :  176 theta값 :  [[-0.08094919  0.94899211 -0.03568157  0.71859947  0.4440491   0.00575575]]\n",
      "학습 횟수 :  177 theta값 :  [[-0.08222526  0.94926911 -0.03557662  0.71711272  0.4432735   0.00575106]]\n",
      "학습 횟수 :  178 theta값 :  [[-0.08349851  0.94954628 -0.03547191  0.71562692  0.44249879  0.00574642]]\n",
      "학습 횟수 :  179 theta값 :  [[-0.08476895  0.94982363 -0.03536746  0.71414207  0.44172497  0.00574182]]\n",
      "학습 횟수 :  180 theta값 :  [[-0.08603658  0.95010117 -0.03526326  0.71265817  0.44095203  0.00573726]]\n",
      "학습 횟수 :  181 theta값 :  [[-0.08730139  0.95037888 -0.03515931  0.71117522  0.44017998  0.00573274]]\n",
      "학습 횟수 :  182 theta값 :  [[-0.08856339  0.95065678 -0.0350556   0.70969324  0.43940882  0.00572826]]\n",
      "학습 횟수 :  183 theta값 :  [[-0.08982257  0.95093486 -0.03495215  0.70821222  0.43863855  0.00572382]]\n",
      "학습 횟수 :  184 theta값 :  [[-0.09107895  0.95121312 -0.03484895  0.70673216  0.43786917  0.00571942]]\n",
      "학습 횟수 :  185 theta값 :  [[-0.09233251  0.95149156 -0.034746    0.70525307  0.43710069  0.00571506]]\n",
      "학습 횟수 :  186 theta값 :  [[-0.09358327  0.95177019 -0.03464329  0.70377495  0.43633311  0.00571075]]\n",
      "학습 횟수 :  187 theta값 :  [[-0.09483121  0.952049   -0.03454084  0.7022978   0.43556642  0.00570647]]\n",
      "학습 횟수 :  188 theta값 :  [[-0.09607635  0.95232799 -0.03443863  0.70082163  0.43480063  0.00570223]]\n",
      "학습 횟수 :  189 theta값 :  [[-0.09731869  0.95260717 -0.03433667  0.69934644  0.43403574  0.00569804]]\n",
      "학습 횟수 :  190 theta값 :  [[-0.09855821  0.95288653 -0.03423496  0.69787223  0.43327175  0.00569388]]\n",
      "학습 횟수 :  191 theta값 :  [[-0.09979494  0.95316607 -0.0341335   0.69639901  0.43250866  0.00568977]]\n",
      "학습 횟수 :  192 theta값 :  [[-0.10102886  0.9534458  -0.03403228  0.69492677  0.43174648  0.0056857 ]]\n",
      "학습 횟수 :  193 theta값 :  [[-0.10225998  0.95372572 -0.03393132  0.69345552  0.43098521  0.00568166]]\n",
      "학습 횟수 :  194 theta값 :  [[-0.10348831  0.95400582 -0.0338306   0.69198527  0.43022484  0.00567767]]\n",
      "학습 횟수 :  195 theta값 :  [[-0.10471383  0.95428611 -0.03373012  0.69051602  0.42946538  0.00567371]]\n",
      "학습 횟수 :  196 theta값 :  [[-0.10593655  0.95456658 -0.0336299   0.68904776  0.42870683  0.0056698 ]]\n",
      "학습 횟수 :  197 theta값 :  [[-0.10715648  0.95484724 -0.03352992  0.6875805   0.42794919  0.00566593]]\n",
      "학습 횟수 :  198 theta값 :  [[-0.10837361  0.95512808 -0.03343018  0.68611426  0.42719246  0.00566209]]\n",
      "학습 횟수 :  199 theta값 :  [[-0.10958795  0.95540912 -0.03333069  0.68464901  0.42643665  0.0056583 ]]\n",
      "학습 횟수 :  200 theta값 :  [[-0.11079949  0.95569034 -0.03323145  0.68318479  0.42568175  0.00565455]]\n",
      "학습 횟수 :  201 theta값 :  [[-0.11200824  0.95597175 -0.03313245  0.68172157  0.42492777  0.00565083]]\n",
      "학습 횟수 :  202 theta값 :  [[-0.1132142   0.95625334 -0.0330337   0.68025937  0.42417471  0.00564716]]\n",
      "학습 횟수 :  203 theta값 :  [[-0.11441737  0.95653513 -0.0329352   0.67879819  0.42342257  0.00564352]]\n",
      "학습 횟수 :  204 theta값 :  [[-0.11561775  0.9568171  -0.03283693  0.67733804  0.42267135  0.00563993]]\n",
      "학습 횟수 :  205 theta값 :  [[-0.11681535  0.95709927 -0.03273892  0.67587891  0.42192105  0.00563637]]\n",
      "학습 횟수 :  206 theta값 :  [[-0.11801015  0.95738162 -0.03264114  0.67442081  0.42117167  0.00563286]]\n",
      "학습 횟수 :  207 theta값 :  [[-0.11920218  0.95766416 -0.03254361  0.67296374  0.42042322  0.00562938]]\n",
      "학습 횟수 :  208 theta값 :  [[-0.12039142  0.95794689 -0.03244633  0.67150771  0.41967569  0.00562594]]\n",
      "학습 횟수 :  209 theta값 :  [[-0.12157787  0.95822981 -0.03234929  0.67005271  0.4189291   0.00562254]]\n",
      "학습 횟수 :  210 theta값 :  [[-0.12276155  0.95851293 -0.03225249  0.66859875  0.41818343  0.00561918]]\n",
      "학습 횟수 :  211 theta값 :  [[-0.12394245  0.95879623 -0.03215593  0.66714584  0.41743869  0.00561586]]\n",
      "학습 횟수 :  212 theta값 :  [[-0.12512056  0.95907972 -0.03205962  0.66569398  0.41669488  0.00561258]]\n",
      "학습 횟수 :  213 theta값 :  [[-0.12629591  0.95936341 -0.03196355  0.66424317  0.41595201  0.00560934]]\n",
      "학습 횟수 :  214 theta값 :  [[-0.12746847  0.95964728 -0.03186772  0.66279341  0.41521007  0.00560614]]\n",
      "학습 횟수 :  215 theta값 :  [[-0.12863826  0.95993135 -0.03177213  0.6613447   0.41446906  0.00560298]]\n",
      "학습 횟수 :  216 theta값 :  [[-0.12980528  0.96021561 -0.03167679  0.65989705  0.41372899  0.00559985]]\n",
      "학습 횟수 :  217 theta값 :  [[-0.13096953  0.96050007 -0.03158169  0.65845047  0.41298986  0.00559676]]\n",
      "학습 횟수 :  218 theta값 :  [[-0.132131    0.96078471 -0.03148682  0.65700495  0.41225167  0.00559372]]\n",
      "학습 횟수 :  219 theta값 :  [[-0.13328971  0.96106955 -0.0313922   0.6555605   0.41151442  0.00559071]]\n",
      "학습 횟수 :  220 theta값 :  [[-0.13444565  0.96135458 -0.03129782  0.65411712  0.41077811  0.00558774]]\n",
      "학습 횟수 :  221 theta값 :  [[-0.13559882  0.96163981 -0.03120368  0.65267482  0.41004275  0.00558481]]\n",
      "학습 횟수 :  222 theta값 :  [[-0.13674923  0.96192523 -0.03110978  0.65123359  0.40930832  0.00558191]]\n",
      "학습 횟수 :  223 theta값 :  [[-0.13789687  0.96221084 -0.03101612  0.64979345  0.40857485  0.00557906]]\n",
      "학습 횟수 :  224 theta값 :  [[-0.13904175  0.96249665 -0.03092271  0.64835439  0.40784232  0.00557624]]\n",
      "학습 횟수 :  225 theta값 :  [[-0.14018387  0.96278265 -0.03082953  0.64691641  0.40711074  0.00557346]]\n",
      "학습 횟수 :  226 theta값 :  [[-0.14132324  0.96306885 -0.03073659  0.64547952  0.40638011  0.00557072]]\n",
      "학습 횟수 :  227 theta값 :  [[-0.14245984  0.96335524 -0.03064388  0.64404373  0.40565043  0.00556802]]\n",
      "학습 횟수 :  228 theta값 :  [[-0.14359369  0.96364182 -0.03055142  0.64260903  0.4049217   0.00556536]]\n",
      "학습 횟수 :  229 theta값 :  [[-0.14472478  0.9639286  -0.0304592   0.64117544  0.40419392  0.00556273]]\n",
      "학습 횟수 :  230 theta값 :  [[-0.14585312  0.96421558 -0.03036721  0.63974294  0.4034671   0.00556015]]\n",
      "학습 횟수 :  231 theta값 :  [[-0.14697871  0.96450275 -0.03027546  0.63831155  0.40274123  0.0055576 ]]\n",
      "학습 횟수 :  232 theta값 :  [[-0.14810155  0.96479012 -0.03018395  0.63688127  0.40201632  0.00555509]]\n",
      "학습 횟수 :  233 theta값 :  [[-0.14922163  0.96507769 -0.03009268  0.6354521   0.40129237  0.00555261]]\n",
      "학습 횟수 :  234 theta값 :  [[-0.15033898  0.96536545 -0.03000164  0.63402405  0.40056938  0.00555018]]\n",
      "학습 횟수 :  235 theta값 :  [[-0.15145357  0.96565341 -0.02991085  0.63259711  0.39984734  0.00554778]]\n",
      "학습 횟수 :  236 theta값 :  [[-0.15256542  0.96594156 -0.02982029  0.6311713   0.39912627  0.00554542]]\n",
      "학습 횟수 :  237 theta값 :  [[-0.15367453  0.96622991 -0.02972996  0.62974661  0.39840617  0.0055431 ]]\n",
      "학습 횟수 :  238 theta값 :  [[-0.1547809   0.96651846 -0.02963987  0.62832305  0.39768702  0.00554081]]\n",
      "학습 횟수 :  239 theta값 :  [[-0.15588452  0.96680721 -0.02955002  0.62690061  0.39696884  0.00553856]]\n",
      "학습 횟수 :  240 theta값 :  [[-0.15698541  0.96709616 -0.0294604   0.62547932  0.39625163  0.00553635]]\n",
      "학습 횟수 :  241 theta값 :  [[-0.15808356  0.9673853  -0.02937102  0.62405916  0.39553538  0.00553418]]\n",
      "학습 횟수 :  242 theta값 :  [[-0.15917898  0.96767464 -0.02928187  0.62264014  0.3948201   0.00553204]]\n",
      "학습 횟수 :  243 theta값 :  [[-0.16027166  0.96796418 -0.02919296  0.62122226  0.3941058   0.00552994]]\n",
      "학습 횟수 :  244 theta값 :  [[-0.16136161  0.96825392 -0.02910429  0.61980553  0.39339246  0.00552788]]\n",
      "학습 횟수 :  245 theta값 :  [[-0.16244884  0.96854385 -0.02901585  0.61838995  0.3926801   0.00552586]]\n",
      "학습 횟수 :  246 theta값 :  [[-0.16353333  0.96883399 -0.02892764  0.61697552  0.3919687   0.00552387]]\n",
      "학습 횟수 :  247 theta값 :  [[-0.16461509  0.96912432 -0.02883967  0.61556225  0.39125829  0.00552192]]\n",
      "학습 횟수 :  248 theta값 :  [[-0.16569413  0.96941486 -0.02875193  0.61415014  0.39054884  0.00552001]]\n",
      "학습 횟수 :  249 theta값 :  [[-0.16677045  0.96970559 -0.02866442  0.61273919  0.38984038  0.00551813]]\n",
      "학습 횟수 :  250 theta값 :  [[-0.16784404  0.96999652 -0.02857715  0.61132941  0.38913289  0.00551629]]\n",
      "학습 횟수 :  251 theta값 :  [[-0.16891492  0.97028765 -0.02849011  0.6099208   0.38842638  0.00551449]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  252 theta값 :  [[-0.16998307  0.97057898 -0.0284033   0.60851336  0.38772085  0.00551272]]\n",
      "학습 횟수 :  253 theta값 :  [[-0.17104851  0.97087052 -0.02831673  0.6071071   0.3870163   0.00551099]]\n",
      "학습 횟수 :  254 theta값 :  [[-0.17211123  0.97116225 -0.02823038  0.60570201  0.38631274  0.00550929]]\n",
      "학습 횟수 :  255 theta값 :  [[-0.17317124  0.97145418 -0.02814427  0.60429811  0.38561015  0.00550764]]\n",
      "학습 횟수 :  256 theta값 :  [[-0.17422854  0.97174631 -0.02805839  0.6028954   0.38490855  0.00550602]]\n",
      "학습 횟수 :  257 theta값 :  [[-0.17528313  0.97203865 -0.02797275  0.60149387  0.38420794  0.00550443]]\n",
      "학습 횟수 :  258 theta값 :  [[-0.17633501  0.97233118 -0.02788733  0.60009353  0.38350831  0.00550288]]\n",
      "학습 횟수 :  259 theta값 :  [[-0.17738418  0.97262392 -0.02780215  0.59869439  0.38280967  0.00550137]]\n",
      "학습 횟수 :  260 theta값 :  [[-0.17843064  0.97291685 -0.02771719  0.59729645  0.38211202  0.0054999 ]]\n",
      "학습 횟수 :  261 theta값 :  [[-0.17947441  0.97320999 -0.02763247  0.59589972  0.38141536  0.00549846]]\n",
      "학습 횟수 :  262 theta값 :  [[-0.18051547  0.97350333 -0.02754797  0.59450418  0.38071968  0.00549705]]\n",
      "학습 횟수 :  263 theta값 :  [[-0.18155383  0.97379687 -0.02746371  0.59310986  0.380025    0.00549568]]\n",
      "학습 횟수 :  264 theta값 :  [[-0.18258949  0.97409061 -0.02737968  0.59171675  0.37933132  0.00549435]]\n",
      "학습 횟수 :  265 theta값 :  [[-0.18362246  0.97438456 -0.02729587  0.59032485  0.37863862  0.00549306]]\n",
      "학습 횟수 :  266 theta값 :  [[-0.18465273  0.9746787  -0.0272123   0.58893417  0.37794692  0.0054918 ]]\n",
      "학습 횟수 :  267 theta값 :  [[-0.18568031  0.97497305 -0.02712895  0.58754472  0.37725622  0.00549057]]\n",
      "학습 횟수 :  268 theta값 :  [[-0.1867052   0.9752676  -0.02704583  0.58615649  0.37656651  0.00548938]]\n",
      "학습 횟수 :  269 theta값 :  [[-0.1877274   0.97556235 -0.02696294  0.58476948  0.3758778   0.00548823]]\n",
      "학습 횟수 :  270 theta값 :  [[-0.18874691  0.9758573  -0.02688028  0.58338371  0.37519009  0.00548711]]\n",
      "학습 횟수 :  271 theta값 :  [[-0.18976374  0.97615246 -0.02679785  0.58199918  0.37450338  0.00548603]]\n",
      "학습 횟수 :  272 theta값 :  [[-0.19077789  0.97644782 -0.02671564  0.58061588  0.37381767  0.00548498]]\n",
      "학습 횟수 :  273 theta값 :  [[-0.19178935  0.97674338 -0.02663367  0.57923383  0.37313296  0.00548397]]\n",
      "학습 횟수 :  274 theta값 :  [[-0.19279813  0.97703914 -0.02655192  0.57785302  0.37244926  0.00548299]]\n",
      "학습 횟수 :  275 theta값 :  [[-0.19380424  0.97733511 -0.02647039  0.57647346  0.37176656  0.00548205]]\n",
      "학습 횟수 :  276 theta값 :  [[-0.19480767  0.97763128 -0.02638909  0.57509515  0.37108486  0.00548114]]\n",
      "학습 횟수 :  277 theta값 :  [[-0.19580842  0.97792765 -0.02630802  0.5737181   0.37040417  0.00548027]]\n",
      "학습 횟수 :  278 theta값 :  [[-0.1968065   0.97822423 -0.02622718  0.57234231  0.36972448  0.00547944]]\n",
      "학습 횟수 :  279 theta값 :  [[-0.19780192  0.97852101 -0.02614656  0.57096778  0.3690458   0.00547863]]\n",
      "학습 횟수 :  280 theta값 :  [[-0.19879466  0.97881799 -0.02606616  0.56959451  0.36836813  0.00547787]]\n",
      "학습 횟수 :  281 theta값 :  [[-0.19978474  0.97911517 -0.02598599  0.56822251  0.36769147  0.00547713]]\n",
      "학습 횟수 :  282 theta값 :  [[-0.20077215  0.97941256 -0.02590605  0.56685179  0.36701582  0.00547644]]\n",
      "학습 횟수 :  283 theta값 :  [[-0.2017569   0.97971015 -0.02582633  0.56548234  0.36634118  0.00547577]]\n",
      "학습 횟수 :  284 theta값 :  [[-0.20273899  0.98000795 -0.02574684  0.56411417  0.36566755  0.00547515]]\n",
      "학습 횟수 :  285 theta값 :  [[-0.20371843  0.98030595 -0.02566757  0.56274728  0.36499494  0.00547455]]\n",
      "학습 횟수 :  286 theta값 :  [[-0.2046952   0.98060415 -0.02558852  0.56138168  0.36432334  0.00547399]]\n",
      "학습 횟수 :  287 theta값 :  [[-0.20566932  0.98090255 -0.0255097   0.56001737  0.36365275  0.00547347]]\n",
      "학습 횟수 :  288 theta값 :  [[-0.20664079  0.98120116 -0.0254311   0.55865435  0.36298318  0.00547298]]\n",
      "학습 횟수 :  289 theta값 :  [[-0.20760961  0.98149998 -0.02535273  0.55729263  0.36231463  0.00547252]]\n",
      "학습 횟수 :  290 theta값 :  [[-0.20857578  0.98179899 -0.02527457  0.5559322   0.3616471   0.0054721 ]]\n",
      "학습 횟수 :  291 theta값 :  [[-0.2095393   0.98209821 -0.02519664  0.55457308  0.36098058  0.00547171]]\n",
      "학습 횟수 :  292 theta값 :  [[-0.21050018  0.98239764 -0.02511894  0.55321527  0.36031508  0.00547136]]\n",
      "학습 횟수 :  293 theta값 :  [[-0.21145841  0.98269727 -0.02504145  0.55185876  0.3596506   0.00547104]]\n",
      "학습 횟수 :  294 theta값 :  [[-0.212414    0.9829971  -0.02496419  0.55050357  0.35898714  0.00547075]]\n",
      "학습 횟수 :  295 theta값 :  [[-0.21336696  0.98329713 -0.02488715  0.54914969  0.35832471  0.0054705 ]]\n",
      "학습 횟수 :  296 theta값 :  [[-0.21431728  0.98359737 -0.02481032  0.54779714  0.35766329  0.00547028]]\n",
      "학습 횟수 :  297 theta값 :  [[-0.21526497  0.98389782 -0.02473373  0.5464459   0.3570029   0.0054701 ]]\n",
      "학습 횟수 :  298 theta값 :  [[-0.21621002  0.98419846 -0.02465735  0.545096    0.35634354  0.00546995]]\n",
      "학습 횟수 :  299 theta값 :  [[-0.21715244  0.98449932 -0.02458119  0.54374742  0.3556852   0.00546983]]\n",
      "학습 횟수 :  300 theta값 :  [[-0.21809224  0.98480037 -0.02450525  0.54240018  0.35502788  0.00546974]]\n",
      "학습 횟수 :  301 theta값 :  [[-0.21902941  0.98510163 -0.02442953  0.54105428  0.35437159  0.00546969]]\n",
      "학습 횟수 :  302 theta값 :  [[-0.21996396  0.9854031  -0.02435403  0.53970971  0.35371633  0.00546968]]\n",
      "학습 횟수 :  303 theta값 :  [[-0.22089588  0.98570476 -0.02427876  0.53836649  0.3530621   0.00546969]]\n",
      "학습 횟수 :  304 theta값 :  [[-0.22182519  0.98600664 -0.0242037   0.53702462  0.35240889  0.00546974]]\n",
      "학습 횟수 :  305 theta값 :  [[-0.22275188  0.98630871 -0.02412886  0.53568409  0.35175672  0.00546982]]\n",
      "학습 횟수 :  306 theta값 :  [[-0.22367595  0.98661099 -0.02405424  0.53434493  0.35110557  0.00546994]]\n",
      "학습 횟수 :  307 theta값 :  [[-0.22459741  0.98691347 -0.02397983  0.53300711  0.35045546  0.00547009]]\n",
      "학습 횟수 :  308 theta값 :  [[-0.22551626  0.98721616 -0.02390565  0.53167066  0.34980638  0.00547027]]\n",
      "학습 횟수 :  309 theta값 :  [[-0.2264325   0.98751905 -0.02383168  0.53033558  0.34915833  0.00547048]]\n",
      "학습 횟수 :  310 theta값 :  [[-0.22734614  0.98782215 -0.02375793  0.52900186  0.34851132  0.00547073]]\n",
      "학습 횟수 :  311 theta값 :  [[-0.22825717  0.98812545 -0.0236844   0.52766951  0.34786534  0.00547101]]\n",
      "학습 횟수 :  312 theta값 :  [[-0.2291656   0.98842895 -0.02361108  0.52633854  0.34722039  0.00547132]]\n",
      "학습 횟수 :  313 theta값 :  [[-0.23007143  0.98873266 -0.02353798  0.52500895  0.34657648  0.00547167]]\n",
      "학습 횟수 :  314 theta값 :  [[-0.23097466  0.98903657 -0.0234651   0.52368074  0.34593361  0.00547204]]\n",
      "학습 횟수 :  315 theta값 :  [[-0.2318753   0.98934068 -0.02339244  0.52235391  0.34529177  0.00547245]]\n",
      "학습 횟수 :  316 theta값 :  [[-0.23277335  0.989645   -0.02331999  0.52102847  0.34465097  0.0054729 ]]\n",
      "학습 횟수 :  317 theta값 :  [[-0.2336688   0.98994952 -0.02324775  0.51970442  0.34401121  0.00547337]]\n",
      "학습 횟수 :  318 theta값 :  [[-0.23456167  0.99025425 -0.02317574  0.51838177  0.34337249  0.00547388]]\n",
      "학습 횟수 :  319 theta값 :  [[-0.23545195  0.99055917 -0.02310393  0.51706052  0.34273481  0.00547442]]\n",
      "학습 횟수 :  320 theta값 :  [[-0.23633965  0.99086431 -0.02303234  0.51574067  0.34209817  0.00547499]]\n",
      "학습 횟수 :  321 theta값 :  [[-0.23722476  0.99116964 -0.02296097  0.51442222  0.34146257  0.00547559]]\n",
      "학습 횟수 :  322 theta값 :  [[-0.2381073   0.99147518 -0.02288981  0.51310519  0.34082801  0.00547623]]\n",
      "학습 횟수 :  323 theta값 :  [[-0.23898726  0.99178092 -0.02281886  0.51178956  0.34019449  0.00547689]]\n",
      "학습 횟수 :  324 theta값 :  [[-0.23986465  0.99208687 -0.02274813  0.51047535  0.33956202  0.00547759]]\n",
      "학습 횟수 :  325 theta값 :  [[-0.24073946  0.99239302 -0.02267761  0.50916257  0.33893059  0.00547832]]\n",
      "학습 횟수 :  326 theta값 :  [[-0.24161171  0.99269937 -0.02260731  0.5078512   0.33830021  0.00547908]]\n",
      "학습 횟수 :  327 theta값 :  [[-0.24248138  0.99300592 -0.02253722  0.50654126  0.33767087  0.00547988]]\n",
      "학습 횟수 :  328 theta값 :  [[-0.2433485   0.99331268 -0.02246734  0.50523275  0.33704257  0.0054807 ]]\n",
      "학습 횟수 :  329 theta값 :  [[-0.24421305  0.99361964 -0.02239767  0.50392567  0.33641532  0.00548156]]\n",
      "학습 횟수 :  330 theta값 :  [[-0.24507504  0.99392681 -0.02232822  0.50262003  0.33578912  0.00548245]]\n",
      "학습 횟수 :  331 theta값 :  [[-0.24593447  0.99423417 -0.02225897  0.50131583  0.33516397  0.00548337]]\n",
      "학습 횟수 :  332 theta값 :  [[-0.24679135  0.99454174 -0.02218994  0.50001307  0.33453986  0.00548432]]\n",
      "학습 횟수 :  333 theta값 :  [[-0.24764568  0.99484951 -0.02212112  0.49871176  0.3339168   0.0054853 ]]\n",
      "학습 횟수 :  334 theta값 :  [[-0.24849746  0.99515748 -0.02205251  0.4974119   0.33329479  0.00548631]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  335 theta값 :  [[-0.24934669  0.99546566 -0.02198412  0.49611349  0.33267384  0.00548736]]\n",
      "학습 횟수 :  336 theta값 :  [[-0.25019337  0.99577404 -0.02191593  0.49481654  0.33205393  0.00548843]]\n",
      "학습 횟수 :  337 theta값 :  [[-0.25103751  0.99608262 -0.02184795  0.49352105  0.33143507  0.00548954]]\n",
      "학습 횟수 :  338 theta값 :  [[-0.25187911  0.9963914  -0.02178018  0.49222702  0.33081726  0.00549067]]\n",
      "학습 횟수 :  339 theta값 :  [[-0.25271818  0.99670038 -0.02171262  0.49093446  0.3302005   0.00549184]]\n",
      "학습 횟수 :  340 theta값 :  [[-0.25355471  0.99700957 -0.02164528  0.48964337  0.3295848   0.00549304]]\n",
      "학습 횟수 :  341 theta값 :  [[-0.2543887   0.99731895 -0.02157814  0.48835375  0.32897015  0.00549426]]\n",
      "학습 횟수 :  342 theta값 :  [[-0.25522017  0.99762854 -0.0215112   0.48706561  0.32835655  0.00549552]]\n",
      "학습 횟수 :  343 theta값 :  [[-0.25604911  0.99793833 -0.02144448  0.48577895  0.327744    0.00549681]]\n",
      "학습 횟수 :  344 theta값 :  [[-0.25687552  0.99824832 -0.02137797  0.48449378  0.32713251  0.00549813]]\n",
      "학습 횟수 :  345 theta값 :  [[-0.25769941  0.99855851 -0.02131166  0.48321009  0.32652208  0.00549948]]\n",
      "학습 횟수 :  346 theta값 :  [[-0.25852079  0.9988689  -0.02124556  0.48192789  0.3259127   0.00550086]]\n",
      "학습 횟수 :  347 theta값 :  [[-0.25933964  0.9991795  -0.02117967  0.48064719  0.32530437  0.00550227]]\n",
      "학습 횟수 :  348 theta값 :  [[-0.26015598  0.99949029 -0.02111398  0.47936798  0.3246971   0.00550371]]\n",
      "학습 횟수 :  349 theta값 :  [[-0.26096981  0.99980128 -0.02104851  0.47809028  0.32409089  0.00550518]]\n",
      "학습 횟수 :  350 theta값 :  [[-0.26178113  1.00011248 -0.02098324  0.47681408  0.32348573  0.00550668]]\n",
      "학습 횟수 :  351 theta값 :  [[-0.26258994  1.00042387 -0.02091817  0.47553938  0.32288163  0.00550821]]\n",
      "학습 횟수 :  352 theta값 :  [[-0.26339625  1.00073547 -0.02085331  0.4742662   0.32227859  0.00550977]]\n",
      "학습 횟수 :  353 theta값 :  [[-0.26420006  1.00104726 -0.02078866  0.47299453  0.32167661  0.00551135]]\n",
      "학습 횟수 :  354 theta값 :  [[-0.26500137  1.00135925 -0.02072421  0.47172438  0.32107568  0.00551297]]\n",
      "학습 횟수 :  355 theta값 :  [[-0.26580019  1.00167145 -0.02065996  0.47045575  0.32047582  0.00551462]]\n",
      "학습 횟수 :  356 theta값 :  [[-0.26659651  1.00198384 -0.02059593  0.46918864  0.31987701  0.0055163 ]]\n",
      "학습 횟수 :  357 theta값 :  [[-0.26739034  1.00229643 -0.02053209  0.46792306  0.31927926  0.005518  ]]\n",
      "학습 횟수 :  358 theta값 :  [[-0.26818168  1.00260922 -0.02046846  0.46665901  0.31868258  0.00551974]]\n",
      "학습 횟수 :  359 theta값 :  [[-0.26897054  1.00292221 -0.02040503  0.46539649  0.31808695  0.0055215 ]]\n",
      "학습 횟수 :  360 theta값 :  [[-0.26975692  1.0032354  -0.02034181  0.46413551  0.31749238  0.0055233 ]]\n",
      "학습 횟수 :  361 theta값 :  [[-0.27054081  1.00354878 -0.02027879  0.46287607  0.31689888  0.00552512]]\n",
      "학습 횟수 :  362 theta값 :  [[-0.27132223  1.00386237 -0.02021598  0.46161818  0.31630643  0.00552697]]\n",
      "학습 횟수 :  363 theta값 :  [[-0.27210118  1.00417615 -0.02015336  0.46036183  0.31571505  0.00552885]]\n",
      "학습 횟수 :  364 theta값 :  [[-0.27287766  1.00449013 -0.02009095  0.45910703  0.31512473  0.00553076]]\n",
      "학습 횟수 :  365 theta값 :  [[-0.27365166  1.00480431 -0.02002874  0.45785379  0.31453547  0.0055327 ]]\n",
      "학습 횟수 :  366 theta값 :  [[-0.27442321  1.00511868 -0.01996673  0.4566021   0.31394728  0.00553466]]\n",
      "학습 횟수 :  367 theta값 :  [[-0.27519229  1.00543325 -0.01990493  0.45535197  0.31336014  0.00553666]]\n",
      "학습 횟수 :  368 theta값 :  [[-0.27595891  1.00574802 -0.01984332  0.45410341  0.31277407  0.00553868]]\n",
      "학습 횟수 :  369 theta값 :  [[-0.27672307  1.00606299 -0.01978192  0.45285641  0.31218906  0.00554073]]\n",
      "학습 횟수 :  370 theta값 :  [[-0.27748478  1.00637815 -0.01972071  0.45161098  0.31160512  0.00554281]]\n",
      "학습 횟수 :  371 theta값 :  [[-0.27824404  1.00669351 -0.01965971  0.45036712  0.31102224  0.00554492]]\n",
      "학습 횟수 :  372 theta값 :  [[-0.27900085  1.00700906 -0.01959891  0.44912484  0.31044043  0.00554706]]\n",
      "학습 횟수 :  373 theta값 :  [[-0.27975521  1.00732481 -0.0195383   0.44788414  0.30985968  0.00554922]]\n",
      "학습 횟수 :  374 theta값 :  [[-0.28050714  1.00764076 -0.0194779   0.44664502  0.30927999  0.00555141]]\n",
      "학습 횟수 :  375 theta값 :  [[-0.28125662  1.0079569  -0.01941769  0.44540749  0.30870137  0.00555363]]\n",
      "학습 횟수 :  376 theta값 :  [[-0.28200367  1.00827324 -0.01935768  0.44417154  0.30812381  0.00555588]]\n",
      "학습 횟수 :  377 theta값 :  [[-0.28274828  1.00858977 -0.01929788  0.44293719  0.30754732  0.00555815]]\n",
      "학습 횟수 :  378 theta값 :  [[-0.28349047  1.0089065  -0.01923827  0.44170443  0.30697189  0.00556046]]\n",
      "학습 횟수 :  379 theta값 :  [[-0.28423022  1.00922342 -0.01917885  0.44047327  0.30639753  0.00556279]]\n",
      "학습 횟수 :  380 theta값 :  [[-0.28496755  1.00954053 -0.01911964  0.43924371  0.30582424  0.00556514]]\n",
      "학습 횟수 :  381 theta값 :  [[-0.28570246  1.00985784 -0.01906062  0.43801576  0.30525201  0.00556753]]\n",
      "학습 횟수 :  382 theta값 :  [[-0.28643496  1.01017534 -0.0190018   0.43678941  0.30468084  0.00556994]]\n",
      "학습 횟수 :  383 theta값 :  [[-0.28716503  1.01049304 -0.01894318  0.43556467  0.30411075  0.00557238]]\n",
      "학습 횟수 :  384 theta값 :  [[-0.2878927   1.01081093 -0.01888475  0.43434155  0.30354171  0.00557485]]\n",
      "학습 횟수 :  385 theta값 :  [[-0.28861795  1.01112901 -0.01882652  0.43312004  0.30297375  0.00557734]]\n",
      "학습 횟수 :  386 theta값 :  [[-0.2893408   1.01144728 -0.01876848  0.43190015  0.30240685  0.00557986]]\n",
      "학습 횟수 :  387 theta값 :  [[-0.29006125  1.01176575 -0.01871064  0.43068189  0.30184102  0.00558241]]\n",
      "학습 횟수 :  388 theta값 :  [[-0.29077929  1.01208441 -0.018653    0.42946525  0.30127625  0.00558498]]\n",
      "학습 횟수 :  389 theta값 :  [[-0.29149494  1.01240326 -0.01859555  0.42825024  0.30071255  0.00558758]]\n",
      "학습 횟수 :  390 theta값 :  [[-0.2922082   1.0127223  -0.01853829  0.42703686  0.30014992  0.00559021]]\n",
      "학습 횟수 :  391 theta값 :  [[-0.29291906  1.01304153 -0.01848123  0.42582512  0.29958836  0.00559286]]\n",
      "학습 횟수 :  392 theta값 :  [[-0.29362754  1.01336095 -0.01842436  0.42461501  0.29902786  0.00559554]]\n",
      "학습 횟수 :  393 theta값 :  [[-0.29433363  1.01368057 -0.01836769  0.42340654  0.29846843  0.00559824]]\n",
      "학습 횟수 :  394 theta값 :  [[-0.29503734  1.01400037 -0.0183112   0.42219972  0.29791006  0.00560098]]\n",
      "학습 횟수 :  395 theta값 :  [[-0.29573867  1.01432037 -0.01825492  0.42099455  0.29735276  0.00560373]]\n",
      "학습 횟수 :  396 theta값 :  [[-0.29643763  1.01464055 -0.01819882  0.41979102  0.29679653  0.00560652]]\n",
      "학습 횟수 :  397 theta값 :  [[-0.29713422  1.01496093 -0.01814292  0.41858915  0.29624137  0.00560933]]\n",
      "학습 횟수 :  398 theta값 :  [[-0.29782844  1.01528149 -0.0180872   0.41738893  0.29568727  0.00561216]]\n",
      "학습 횟수 :  399 theta값 :  [[-0.29852029  1.01560224 -0.01803168  0.41619037  0.29513424  0.00561503]]\n",
      "학습 횟수 :  400 theta값 :  [[-0.29920978  1.01592319 -0.01797636  0.41499347  0.29458228  0.00561791]]\n",
      "학습 횟수 :  401 theta값 :  [[-0.29989692  1.01624431 -0.01792122  0.41379823  0.29403138  0.00562082]]\n",
      "학습 횟수 :  402 theta값 :  [[-0.30058169  1.01656563 -0.01786627  0.41260466  0.29348155  0.00562376]]\n",
      "학습 횟수 :  403 theta값 :  [[-0.30126412  1.01688714 -0.01781151  0.41141277  0.29293279  0.00562673]]\n",
      "학습 횟수 :  404 theta값 :  [[-0.3019442   1.01720883 -0.01775695  0.41022254  0.2923851   0.00562971]]\n",
      "학습 횟수 :  405 theta값 :  [[-0.30262193  1.01753071 -0.01770257  0.40903399  0.29183847  0.00563273]]\n",
      "학습 횟수 :  406 theta값 :  [[-0.30329732  1.01785277 -0.01764838  0.40784712  0.29129291  0.00563577]]\n",
      "학습 횟수 :  407 theta값 :  [[-0.30397037  1.01817502 -0.01759438  0.40666193  0.29074841  0.00563883]]\n",
      "학습 횟수 :  408 theta값 :  [[-0.30464108  1.01849746 -0.01754057  0.40547842  0.29020498  0.00564192]]\n",
      "학습 횟수 :  409 theta값 :  [[-0.30530947  1.01882008 -0.01748695  0.4042966   0.28966262  0.00564503]]\n",
      "학습 횟수 :  410 theta값 :  [[-0.30597552  1.01914289 -0.01743352  0.40311646  0.28912132  0.00564817]]\n",
      "학습 횟수 :  411 theta값 :  [[-0.30663925  1.01946589 -0.01738027  0.40193802  0.28858109  0.00565133]]\n",
      "학습 횟수 :  412 theta값 :  [[-0.30730066  1.01978907 -0.01732721  0.40076128  0.28804192  0.00565452]]\n",
      "학습 횟수 :  413 theta값 :  [[-0.30795975  1.02011243 -0.01727434  0.39958623  0.28750382  0.00565773]]\n",
      "학습 횟수 :  414 theta값 :  [[-0.30861652  1.02043598 -0.01722166  0.39841288  0.28696679  0.00566097]]\n",
      "학습 횟수 :  415 theta값 :  [[-0.30927098  1.02075971 -0.01716916  0.39724124  0.28643082  0.00566423]]\n",
      "학습 횟수 :  416 theta값 :  [[-0.30992314  1.02108362 -0.01711685  0.3960713   0.28589591  0.00566751]]\n",
      "학습 횟수 :  417 theta값 :  [[-0.31057299  1.02140772 -0.01706472  0.39490306  0.28536207  0.00567082]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  418 theta값 :  [[-0.31122053  1.02173199 -0.01701278  0.39373654  0.2848293   0.00567415]]\n",
      "학습 횟수 :  419 theta값 :  [[-0.31186579  1.02205645 -0.01696103  0.39257173  0.28429759  0.00567751]]\n",
      "학습 횟수 :  420 theta값 :  [[-0.31250874  1.0223811  -0.01690946  0.39140864  0.28376695  0.00568088]]\n",
      "학습 횟수 :  421 theta값 :  [[-0.31314941  1.02270592 -0.01685807  0.39024726  0.28323736  0.00568429]]\n",
      "학습 횟수 :  422 theta값 :  [[-0.31378779  1.02303093 -0.01680687  0.38908761  0.28270885  0.00568771]]\n",
      "학습 횟수 :  423 theta값 :  [[-0.31442388  1.02335611 -0.01675585  0.38792968  0.28218139  0.00569116]]\n",
      "학습 횟수 :  424 theta값 :  [[-0.3150577   1.02368148 -0.01670502  0.38677347  0.281655    0.00569464]]\n",
      "학습 횟수 :  425 theta값 :  [[-0.31568924  1.02400703 -0.01665437  0.385619    0.28112967  0.00569813]]\n",
      "학습 횟수 :  426 theta값 :  [[-0.3163185   1.02433275 -0.0166039   0.38446625  0.28060541  0.00570165]]\n",
      "학습 횟수 :  427 theta값 :  [[-0.3169455   1.02465866 -0.01655361  0.38331524  0.28008221  0.0057052 ]]\n",
      "학습 횟수 :  428 theta값 :  [[-0.31757023  1.02498474 -0.01650351  0.38216596  0.27956006  0.00570876]]\n",
      "학습 횟수 :  429 theta값 :  [[-0.3181927   1.025311   -0.01645359  0.38101842  0.27903899  0.00571235]]\n",
      "학습 횟수 :  430 theta값 :  [[-0.31881291  1.02563744 -0.01640385  0.37987262  0.27851897  0.00571596]]\n",
      "학습 횟수 :  431 theta값 :  [[-0.31943086  1.02596406 -0.01635429  0.37872857  0.27800001  0.00571959]]\n",
      "학습 횟수 :  432 theta값 :  [[-0.32004657  1.02629086 -0.01630491  0.37758626  0.27748212  0.00572325]]\n",
      "학습 횟수 :  433 theta값 :  [[-0.32066002  1.02661783 -0.01625571  0.3764457   0.27696528  0.00572693]]\n",
      "학습 횟수 :  434 theta값 :  [[-0.32127124  1.02694498 -0.0162067   0.37530688  0.27644951  0.00573063]]\n",
      "학습 횟수 :  435 theta값 :  [[-0.32188021  1.0272723  -0.01615786  0.37416982  0.27593479  0.00573435]]\n",
      "학습 횟수 :  436 theta값 :  [[-0.32248695  1.0275998  -0.0161092   0.37303452  0.27542113  0.0057381 ]]\n",
      "학습 횟수 :  437 theta값 :  [[-0.32309145  1.02792748 -0.01606072  0.37190097  0.27490854  0.00574187]]\n",
      "학습 횟수 :  438 theta값 :  [[-0.32369373  1.02825533 -0.01601242  0.37076918  0.274397    0.00574565]]\n",
      "학습 횟수 :  439 theta값 :  [[-0.32429378  1.02858336 -0.0159643   0.36963915  0.27388652  0.00574946]]\n",
      "학습 횟수 :  440 theta값 :  [[-0.3248916   1.02891155 -0.01591636  0.36851088  0.27337709  0.0057533 ]]\n",
      "학습 횟수 :  441 theta값 :  [[-0.32548721  1.02923993 -0.01586859  0.36738438  0.27286873  0.00575715]]\n",
      "학습 횟수 :  442 theta값 :  [[-0.32608061  1.02956847 -0.015821    0.36625965  0.27236142  0.00576103]]\n",
      "학습 횟수 :  443 theta값 :  [[-0.3266718   1.02989719 -0.01577359  0.36513669  0.27185516  0.00576492]]\n",
      "학습 횟수 :  444 theta값 :  [[-0.32726078  1.03022608 -0.01572635  0.3640155   0.27134997  0.00576884]]\n",
      "학습 횟수 :  445 theta값 :  [[-0.32784756  1.03055515 -0.0156793   0.36289608  0.27084582  0.00577278]]\n",
      "학습 횟수 :  446 theta값 :  [[-0.32843214  1.03088438 -0.01563241  0.36177845  0.27034274  0.00577674]]\n",
      "학습 횟수 :  447 theta값 :  [[-0.32901452  1.03121379 -0.01558571  0.36066258  0.2698407   0.00578072]]\n",
      "학습 횟수 :  448 theta값 :  [[-0.32959471  1.03154336 -0.01553918  0.3595485   0.26933972  0.00578472]]\n",
      "학습 횟수 :  449 theta값 :  [[-0.33017272  1.03187311 -0.01549282  0.35843621  0.2688398   0.00578875]]\n",
      "학습 횟수 :  450 theta값 :  [[-0.33074854  1.03220302 -0.01544664  0.35732569  0.26834092  0.00579279]]\n",
      "학습 횟수 :  451 theta값 :  [[-0.33132219  1.03253311 -0.01540063  0.35621697  0.2678431   0.00579685]]\n",
      "학습 횟수 :  452 theta값 :  [[-0.33189366  1.03286337 -0.0153548   0.35511003  0.26734633  0.00580094]]\n",
      "학습 횟수 :  453 theta값 :  [[-0.33246295  1.03319379 -0.01530914  0.35400488  0.26685061  0.00580504]]\n",
      "학습 횟수 :  454 theta값 :  [[-0.33303008  1.03352438 -0.01526365  0.35290152  0.26635595  0.00580917]]\n",
      "학습 횟수 :  455 theta값 :  [[-0.33359505  1.03385514 -0.01521834  0.35179996  0.26586233  0.00581331]]\n",
      "학습 횟수 :  456 theta값 :  [[-0.33415786  1.03418606 -0.0151732   0.35070019  0.26536976  0.00581748]]\n",
      "학습 횟수 :  457 theta값 :  [[-0.33471851  1.03451716 -0.01512823  0.34960222  0.26487824  0.00582166]]\n",
      "학습 횟수 :  458 theta값 :  [[-0.335277    1.03484842 -0.01508343  0.34850605  0.26438776  0.00582586]]\n",
      "학습 횟수 :  459 theta값 :  [[-0.33583336  1.03517984 -0.01503881  0.34741169  0.26389834  0.00583009]]\n",
      "학습 횟수 :  460 theta값 :  [[-0.33638756  1.03551143 -0.01499436  0.34631912  0.26340996  0.00583433]]\n",
      "학습 횟수 :  461 theta값 :  [[-0.33693963  1.03584319 -0.01495007  0.34522836  0.26292263  0.00583859]]\n",
      "학습 횟수 :  462 theta값 :  [[-0.33748956  1.03617511 -0.01490596  0.34413941  0.26243634  0.00584287]]\n",
      "학습 횟수 :  463 theta값 :  [[-0.33803736  1.03650719 -0.01486202  0.34305226  0.2619511   0.00584718]]\n",
      "학습 횟수 :  464 theta값 :  [[-0.33858303  1.03683944 -0.01481824  0.34196693  0.2614669   0.0058515 ]]\n",
      "학습 횟수 :  465 theta값 :  [[-0.33912658  1.03717185 -0.01477464  0.34088341  0.26098375  0.00585583]]\n",
      "학습 횟수 :  466 theta값 :  [[-0.33966801  1.03750442 -0.01473121  0.3398017   0.26050163  0.00586019]]\n",
      "학습 횟수 :  467 theta값 :  [[-0.34020733  1.03783715 -0.01468794  0.3387218   0.26002056  0.00586457]]\n",
      "학습 횟수 :  468 theta값 :  [[-0.34074453  1.03817005 -0.01464485  0.33764372  0.25954053  0.00586896]]\n",
      "학습 횟수 :  469 theta값 :  [[-0.34127962  1.03850311 -0.01460192  0.33656746  0.25906155  0.00587338]]\n",
      "학습 횟수 :  470 theta값 :  [[-0.34181261  1.03883633 -0.01455915  0.33549302  0.2585836   0.00587781]]\n",
      "학습 횟수 :  471 theta값 :  [[-0.34234351  1.0391697  -0.01451656  0.3344204   0.25810669  0.00588226]]\n",
      "학습 횟수 :  472 theta값 :  [[-0.34287231  1.03950324 -0.01447413  0.3333496   0.25763082  0.00588673]]\n",
      "학습 횟수 :  473 theta값 :  [[-0.34339901  1.03983694 -0.01443187  0.33228063  0.25715598  0.00589121]]\n",
      "학습 횟수 :  474 theta값 :  [[-0.34392363  1.0401708  -0.01438978  0.33121348  0.25668218  0.00589572]]\n",
      "학습 횟수 :  475 theta값 :  [[-0.34444617  1.04050481 -0.01434785  0.33014816  0.25620942  0.00590024]]\n",
      "학습 횟수 :  476 theta값 :  [[-0.34496663  1.04083899 -0.01430609  0.32908467  0.2557377   0.00590478]]\n",
      "학습 횟수 :  477 theta값 :  [[-0.34548502  1.04117332 -0.01426449  0.32802301  0.255267    0.00590933]]\n",
      "학습 횟수 :  478 theta값 :  [[-0.34600133  1.0415078  -0.01422306  0.32696318  0.25479735  0.00591391]]\n",
      "학습 횟수 :  479 theta값 :  [[-0.34651558  1.04184245 -0.01418179  0.32590518  0.25432872  0.0059185 ]]\n",
      "학습 횟수 :  480 theta값 :  [[-0.34702777  1.04217725 -0.01414068  0.32484901  0.25386113  0.00592311]]\n",
      "학습 횟수 :  481 theta값 :  [[-0.3475379   1.0425122  -0.01409974  0.32379468  0.25339456  0.00592774]]\n",
      "학습 횟수 :  482 theta값 :  [[-0.34804598  1.04284731 -0.01405896  0.32274218  0.25292903  0.00593238]]\n",
      "학습 횟수 :  483 theta값 :  [[-0.34855201  1.04318257 -0.01401835  0.32169153  0.25246452  0.00593704]]\n",
      "학습 횟수 :  484 theta값 :  [[-0.34905599  1.04351799 -0.0139779   0.32064271  0.25200105  0.00594172]]\n",
      "학습 횟수 :  485 theta값 :  [[-0.34955794  1.04385356 -0.01393761  0.31959573  0.2515386   0.00594641]]\n",
      "학습 횟수 :  486 theta값 :  [[-0.35005785  1.04418929 -0.01389748  0.31855059  0.25107718  0.00595112]]\n",
      "학습 횟수 :  487 theta값 :  [[-0.35055572  1.04452517 -0.01385751  0.31750729  0.25061678  0.00595584]]\n",
      "학습 횟수 :  488 theta값 :  [[-0.35105157  1.0448612  -0.01381771  0.31646584  0.25015741  0.00596059]]\n",
      "학습 횟수 :  489 theta값 :  [[-0.3515454   1.04519738 -0.01377807  0.31542623  0.24969906  0.00596534]]\n",
      "학습 횟수 :  490 theta값 :  [[-0.35203721  1.04553371 -0.01373858  0.31438846  0.24924173  0.00597012]]\n",
      "학습 횟수 :  491 theta값 :  [[-0.352527    1.04587019 -0.01369926  0.31335254  0.24878543  0.00597491]]\n",
      "학습 횟수 :  492 theta값 :  [[-0.35301478  1.04620682 -0.01366009  0.31231847  0.24833015  0.00597971]]\n",
      "학습 횟수 :  493 theta값 :  [[-0.35350056  1.0465436  -0.01362109  0.31128625  0.24787588  0.00598454]]\n",
      "학습 횟수 :  494 theta값 :  [[-0.35398434  1.04688053 -0.01358224  0.31025587  0.24742264  0.00598937]]\n",
      "학습 횟수 :  495 theta값 :  [[-0.35446612  1.04721761 -0.01354356  0.30922735  0.24697041  0.00599423]]\n",
      "학습 횟수 :  496 theta값 :  [[-0.3549459   1.04755484 -0.01350503  0.30820067  0.2465192   0.00599909]]\n",
      "학습 횟수 :  497 theta값 :  [[-0.3554237   1.04789221 -0.01346666  0.30717585  0.24606901  0.00600398]]\n",
      "학습 횟수 :  498 theta값 :  [[-0.35589951  1.04822973 -0.01342844  0.30615288  0.24561983  0.00600887]]\n",
      "학습 횟수 :  499 theta값 :  [[-0.35637335  1.0485674  -0.01339039  0.30513176  0.24517166  0.00601379]]\n",
      "학습 횟수 :  500 theta값 :  [[-0.35684521  1.04890522 -0.01335249  0.30411249  0.24472451  0.00601871]]\n",
      "학습 횟수 :  501 theta값 :  [[-0.3573151   1.04924317 -0.01331475  0.30309508  0.24427837  0.00602366]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  502 theta값 :  [[-0.35778302  1.04958128 -0.01327716  0.30207953  0.24383324  0.00602861]]\n",
      "학습 횟수 :  503 theta값 :  [[-0.35824898  1.04991953 -0.01323973  0.30106583  0.24338912  0.00603358]]\n",
      "학습 횟수 :  504 theta값 :  [[-0.35871298  1.05025792 -0.01320245  0.30005399  0.24294601  0.00603857]]\n",
      "학습 횟수 :  505 theta값 :  [[-0.35917503  1.05059645 -0.01316533  0.299044    0.2425039   0.00604357]]\n",
      "학습 횟수 :  506 theta값 :  [[-0.35963513  1.05093513 -0.01312837  0.29803588  0.2420628   0.00604858]]\n",
      "학습 횟수 :  507 theta값 :  [[-0.36009329  1.05127395 -0.01309155  0.29702961  0.24162271  0.00605361]]\n",
      "학습 횟수 :  508 theta값 :  [[-0.36054951  1.05161291 -0.0130549   0.2960252   0.24118362  0.00605865]]\n",
      "학습 횟수 :  509 theta값 :  [[-0.36100379  1.05195202 -0.01301839  0.29502265  0.24074553  0.00606371]]\n",
      "학습 횟수 :  510 theta값 :  [[-0.36145615  1.05229126 -0.01298204  0.29402196  0.24030844  0.00606878]]\n",
      "학습 횟수 :  511 theta값 :  [[-0.36190657  1.05263064 -0.01294584  0.29302313  0.23987236  0.00607386]]\n",
      "학습 횟수 :  512 theta값 :  [[-0.36235508  1.05297017 -0.01290979  0.29202616  0.23943727  0.00607895]]\n",
      "학습 횟수 :  513 theta값 :  [[-0.36280166  1.05330983 -0.0128739   0.29103105  0.23900319  0.00608406]]\n",
      "학습 횟수 :  514 theta값 :  [[-0.36324634  1.05364963 -0.01283816  0.2900378   0.2385701   0.00608918]]\n",
      "학습 횟수 :  515 theta값 :  [[-0.36368911  1.05398957 -0.01280257  0.28904642  0.238138    0.00609432]]\n",
      "학습 횟수 :  516 theta값 :  [[-0.36412997  1.05432965 -0.01276713  0.2880569   0.2377069   0.00609947]]\n",
      "학습 횟수 :  517 theta값 :  [[-0.36456894  1.05466986 -0.01273184  0.28706924  0.2372768   0.00610463]]\n",
      "학습 횟수 :  518 theta값 :  [[-0.36500601  1.05501021 -0.0126967   0.28608344  0.23684768  0.0061098 ]]\n",
      "학습 횟수 :  519 theta값 :  [[-0.36544119  1.0553507  -0.01266171  0.2850995   0.23641956  0.00611498]]\n",
      "학습 횟수 :  520 theta값 :  [[-0.36587448  1.05569132 -0.01262686  0.28411743  0.23599243  0.00612018]]\n",
      "학습 횟수 :  521 theta값 :  [[-0.3663059   1.05603208 -0.01259217  0.28313723  0.23556628  0.00612539]]\n",
      "학습 횟수 :  522 theta값 :  [[-0.36673544  1.05637297 -0.01255763  0.28215888  0.23514113  0.00613061]]\n",
      "학습 횟수 :  523 theta값 :  [[-0.3671631   1.05671399 -0.01252324  0.2811824   0.23471696  0.00613585]]\n",
      "학습 횟수 :  524 theta값 :  [[-0.36758891  1.05705515 -0.01248899  0.28020778  0.23429377  0.00614109]]\n",
      "학습 횟수 :  525 theta값 :  [[-0.36801284  1.05739644 -0.01245489  0.27923503  0.23387157  0.00614635]]\n",
      "학습 횟수 :  526 theta값 :  [[-0.36843492  1.05773786 -0.01242094  0.27826414  0.23345035  0.00615162]]\n",
      "학습 횟수 :  527 theta값 :  [[-0.36885515  1.05807942 -0.01238713  0.27729512  0.23303011  0.0061569 ]]\n",
      "학습 횟수 :  528 theta값 :  [[-0.36927353  1.0584211  -0.01235347  0.27632796  0.23261085  0.00616219]]\n",
      "학습 횟수 :  529 theta값 :  [[-0.36969007  1.05876292 -0.01231996  0.27536266  0.23219257  0.00616749]]\n",
      "학습 횟수 :  530 theta값 :  [[-0.37010476  1.05910487 -0.01228659  0.27439923  0.23177526  0.00617281]]\n",
      "학습 횟수 :  531 theta값 :  [[-0.37051762  1.05944694 -0.01225337  0.27343766  0.23135893  0.00617813]]\n",
      "학습 횟수 :  532 theta값 :  [[-0.37092865  1.05978915 -0.0122203   0.27247795  0.23094358  0.00618347]]\n",
      "학습 횟수 :  533 theta값 :  [[-0.37133786  1.06013148 -0.01218736  0.27152011  0.2305292   0.00618881]]\n",
      "학습 횟수 :  534 theta값 :  [[-0.37174525  1.06047394 -0.01215458  0.27056413  0.23011579  0.00619417]]\n",
      "학습 횟수 :  535 theta값 :  [[-0.37215081  1.06081653 -0.01212193  0.26961001  0.22970335  0.00619954]]\n",
      "학습 횟수 :  536 theta값 :  [[-0.37255457  1.06115925 -0.01208943  0.26865775  0.22929188  0.00620491]]\n",
      "학습 횟수 :  537 theta값 :  [[-0.37295652  1.06150209 -0.01205707  0.26770736  0.22888138  0.0062103 ]]\n",
      "학습 횟수 :  538 theta값 :  [[-0.37335667  1.06184506 -0.01202486  0.26675883  0.22847184  0.0062157 ]]\n",
      "학습 횟수 :  539 theta값 :  [[-0.37375503  1.06218815 -0.01199279  0.26581216  0.22806327  0.00622111]]\n",
      "학습 횟수 :  540 theta값 :  [[-0.37415158  1.06253137 -0.01196086  0.26486736  0.22765566  0.00622652]]\n",
      "학습 횟수 :  541 theta값 :  [[-0.37454636  1.06287471 -0.01192907  0.26392441  0.22724901  0.00623195]]\n",
      "학습 횟수 :  542 theta값 :  [[-0.37493934  1.06321817 -0.01189742  0.26298333  0.22684333  0.00623739]]\n",
      "학습 횟수 :  543 theta값 :  [[-0.37533055  1.06356176 -0.01186591  0.2620441   0.2264386   0.00624283]]\n",
      "학습 횟수 :  544 theta값 :  [[-0.37571999  1.06390547 -0.01183455  0.26110674  0.22603483  0.00624829]]\n",
      "학습 횟수 :  545 theta값 :  [[-0.37610766  1.0642493  -0.01180332  0.26017123  0.22563202  0.00625375]]\n",
      "학습 횟수 :  546 theta값 :  [[-0.37649356  1.06459326 -0.01177223  0.25923758  0.22523016  0.00625923]]\n",
      "학습 횟수 :  547 theta값 :  [[-0.3768777   1.06493733 -0.01174129  0.25830579  0.22482925  0.00626471]]\n",
      "학습 횟수 :  548 theta값 :  [[-0.37726009  1.06528152 -0.01171048  0.25737586  0.2244293   0.0062702 ]]\n",
      "학습 횟수 :  549 theta값 :  [[-0.37764073  1.06562584 -0.01167981  0.25644779  0.2240303   0.0062757 ]]\n",
      "학습 횟수 :  550 theta값 :  [[-0.37801962  1.06597027 -0.01164928  0.25552157  0.22363224  0.00628121]]\n",
      "학습 횟수 :  551 theta값 :  [[-0.37839677  1.06631483 -0.01161889  0.25459721  0.22323514  0.00628673]]\n",
      "학습 횟수 :  552 theta값 :  [[-0.37877218  1.0666595  -0.01158863  0.2536747   0.22283898  0.00629225]]\n",
      "학습 횟수 :  553 theta값 :  [[-0.37914587  1.06700428 -0.01155851  0.25275405  0.22244376  0.00629779]]\n",
      "학습 횟수 :  554 theta값 :  [[-0.37951782  1.06734919 -0.01152853  0.25183525  0.22204949  0.00630333]]\n",
      "학습 횟수 :  555 theta값 :  [[-0.37988806  1.06769421 -0.01149868  0.2509183   0.22165616  0.00630888]]\n",
      "학습 횟수 :  556 theta값 :  [[-0.38025658  1.06803935 -0.01146897  0.25000321  0.22126377  0.00631444]]\n",
      "학습 횟수 :  557 theta값 :  [[-0.38062338  1.0683846  -0.0114394   0.24908996  0.22087231  0.00632   ]]\n",
      "학습 횟수 :  558 theta값 :  [[-0.38098848  1.06872997 -0.01140996  0.24817857  0.2204818   0.00632558]]\n",
      "학습 횟수 :  559 theta값 :  [[-0.38135187  1.06907545 -0.01138066  0.24726903  0.22009221  0.00633116]]\n",
      "학습 횟수 :  560 theta값 :  [[-0.38171357  1.06942105 -0.01135149  0.24636133  0.21970357  0.00633675]]\n",
      "학습 횟수 :  561 theta값 :  [[-0.38207357  1.06976675 -0.01132245  0.24545549  0.21931585  0.00634234]]\n",
      "학습 횟수 :  562 theta값 :  [[-0.38243189  1.07011258 -0.01129355  0.24455149  0.21892907  0.00634794]]\n",
      "학습 횟수 :  563 theta값 :  [[-0.38278852  1.07045851 -0.01126478  0.24364933  0.21854321  0.00635355]]\n",
      "학습 횟수 :  564 theta값 :  [[-0.38314347  1.07080455 -0.01123615  0.24274902  0.21815828  0.00635917]]\n",
      "학습 횟수 :  565 theta값 :  [[-0.38349675  1.07115071 -0.01120764  0.24185055  0.21777428  0.00636479]]\n",
      "학습 횟수 :  566 theta값 :  [[-0.38384835  1.07149698 -0.01117927  0.24095393  0.2173912   0.00637042]]\n",
      "학습 횟수 :  567 theta값 :  [[-0.3841983   1.07184335 -0.01115103  0.24005915  0.21700905  0.00637606]]\n",
      "학습 횟수 :  568 theta값 :  [[-0.38454658  1.07218984 -0.01112293  0.23916621  0.21662781  0.0063817 ]]\n",
      "학습 횟수 :  569 theta값 :  [[-0.38489321  1.07253643 -0.01109495  0.2382751   0.2162475   0.00638735]]\n",
      "학습 횟수 :  570 theta값 :  [[-0.38523818  1.07288314 -0.01106711  0.23738584  0.2158681   0.006393  ]]\n",
      "학습 횟수 :  571 theta값 :  [[-0.38558152  1.07322995 -0.01103939  0.23649841  0.21548962  0.00639867]]\n",
      "학습 횟수 :  572 theta값 :  [[-0.38592321  1.07357687 -0.01101181  0.23561282  0.21511206  0.00640433]]\n",
      "학습 횟수 :  573 theta값 :  [[-0.38626326  1.07392389 -0.01098435  0.23472906  0.2147354   0.00641001]]\n",
      "학습 횟수 :  574 theta값 :  [[-0.38660168  1.07427102 -0.01095703  0.23384714  0.21435966  0.00641568]]\n",
      "학습 횟수 :  575 theta값 :  [[-0.38693848  1.07461826 -0.01092983  0.23296704  0.21398483  0.00642137]]\n",
      "학습 횟수 :  576 theta값 :  [[-0.38727365  1.0749656  -0.01090276  0.23208878  0.21361091  0.00642706]]\n",
      "학습 횟수 :  577 theta값 :  [[-0.38760721  1.07531304 -0.01087582  0.23121235  0.21323789  0.00643275]]\n",
      "학습 횟수 :  578 theta값 :  [[-0.38793916  1.07566059 -0.01084901  0.23033774  0.21286577  0.00643845]]\n",
      "학습 횟수 :  579 theta값 :  [[-0.3882695   1.07600825 -0.01082232  0.22946497  0.21249457  0.00644416]]\n",
      "학습 횟수 :  580 theta값 :  [[-0.38859823  1.076356   -0.01079576  0.22859401  0.21212426  0.00644987]]\n",
      "학습 횟수 :  581 theta값 :  [[-0.38892537  1.07670386 -0.01076933  0.22772488  0.21175485  0.00645558]]\n",
      "학습 횟수 :  582 theta값 :  [[-0.38925091  1.07705182 -0.01074303  0.22685758  0.21138634  0.0064613 ]]\n",
      "학습 횟수 :  583 theta값 :  [[-0.38957487  1.07739988 -0.01071685  0.22599209  0.21101872  0.00646703]]\n",
      "학습 횟수 :  584 theta값 :  [[-0.38989724  1.07774804 -0.0106908   0.22512842  0.210652    0.00647276]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  585 theta값 :  [[-0.39021803  1.07809631 -0.01066487  0.22426657  0.21028618  0.00647849]]\n",
      "학습 횟수 :  586 theta값 :  [[-0.39053725  1.07844467 -0.01063906  0.22340653  0.20992124  0.00648423]]\n",
      "학습 횟수 :  587 theta값 :  [[-0.39085491  1.07879313 -0.01061338  0.22254831  0.2095572   0.00648997]]\n",
      "학습 횟수 :  588 theta값 :  [[-0.39117099  1.07914169 -0.01058783  0.22169191  0.20919404  0.00649571]]\n",
      "학습 횟수 :  589 theta값 :  [[-0.39148552  1.07949034 -0.0105624   0.22083731  0.20883176  0.00650146]]\n",
      "학습 횟수 :  590 theta값 :  [[-0.39179849  1.0798391  -0.01053709  0.21998452  0.20847038  0.00650722]]\n",
      "학습 횟수 :  591 theta값 :  [[-0.39210991  1.08018795 -0.0105119   0.21913355  0.20810987  0.00651298]]\n",
      "학습 횟수 :  592 theta값 :  [[-0.39241979  1.0805369  -0.01048684  0.21828437  0.20775025  0.00651874]]\n",
      "학습 횟수 :  593 theta값 :  [[-0.39272812  1.08088594 -0.0104619   0.217437    0.2073915   0.0065245 ]]\n",
      "학습 횟수 :  594 theta값 :  [[-0.39303493  1.08123508 -0.01043708  0.21659144  0.20703363  0.00653027]]\n",
      "학습 횟수 :  595 theta값 :  [[-0.39334019  1.08158431 -0.01041239  0.21574767  0.20667664  0.00653604]]\n",
      "학습 횟수 :  596 theta값 :  [[-0.39364394  1.08193364 -0.01038781  0.21490571  0.20632052  0.00654181]]\n",
      "학습 횟수 :  597 theta값 :  [[-0.39394616  1.08228306 -0.01036336  0.21406554  0.20596528  0.00654759]]\n",
      "학습 횟수 :  598 theta값 :  [[-0.39424687  1.08263258 -0.01033902  0.21322717  0.2056109   0.00655337]]\n",
      "학습 횟수 :  599 theta값 :  [[-0.39454606  1.08298218 -0.01031481  0.21239059  0.20525739  0.00655916]]\n",
      "학습 횟수 :  600 theta값 :  [[-0.39484375  1.08333188 -0.01029071  0.2115558   0.20490475  0.00656494]]\n",
      "학습 횟수 :  601 theta값 :  [[-0.39513993  1.08368167 -0.01026673  0.2107228   0.20455298  0.00657073]]\n",
      "학습 횟수 :  602 theta값 :  [[-0.39543462  1.08403155 -0.01024288  0.20989159  0.20420207  0.00657652]]\n",
      "학습 횟수 :  603 theta값 :  [[-0.39572781  1.08438153 -0.01021914  0.20906216  0.20385202  0.00658232]]\n",
      "학습 횟수 :  604 theta값 :  [[-0.39601952  1.08473159 -0.01019552  0.20823452  0.20350282  0.00658811]]\n",
      "학습 횟수 :  605 theta값 :  [[-0.39630974  1.08508174 -0.01017202  0.20740866  0.20315449  0.00659391]]\n",
      "학습 횟수 :  606 theta값 :  [[-0.39659848  1.08543198 -0.01014863  0.20658458  0.20280701  0.00659971]]\n",
      "학습 횟수 :  607 theta값 :  [[-0.39688575  1.08578231 -0.01012536  0.20576228  0.20246039  0.00660551]]\n",
      "학습 횟수 :  608 theta값 :  [[-0.39717155  1.08613272 -0.01010221  0.20494175  0.20211462  0.00661132]]\n",
      "학습 횟수 :  609 theta값 :  [[-0.39745589  1.08648323 -0.01007918  0.204123    0.2017697   0.00661712]]\n",
      "학습 횟수 :  610 theta값 :  [[-0.39773877  1.08683382 -0.01005626  0.20330602  0.20142563  0.00662293]]\n",
      "학습 횟수 :  611 theta값 :  [[-0.39802019  1.08718449 -0.01003346  0.20249081  0.20108241  0.00662874]]\n",
      "학습 횟수 :  612 theta값 :  [[-0.39830016  1.08753525 -0.01001077  0.20167736  0.20074003  0.00663455]]\n",
      "학습 횟수 :  613 theta값 :  [[-0.39857869  1.0878861  -0.00998819  0.20086568  0.20039849  0.00664036]]\n",
      "학습 횟수 :  614 theta값 :  [[-0.39885578  1.08823703 -0.00996574  0.20005576  0.2000578   0.00664618]]\n",
      "학습 횟수 :  615 theta값 :  [[-0.39913143  1.08858805 -0.00994339  0.19924761  0.19971794  0.00665199]]\n",
      "학습 횟수 :  616 theta값 :  [[-0.39940565  1.08893915 -0.00992116  0.19844121  0.19937893  0.00665781]]\n",
      "학습 횟수 :  617 theta값 :  [[-0.39967844  1.08929033 -0.00989904  0.19763657  0.19904075  0.00666363]]\n",
      "학습 횟수 :  618 theta값 :  [[-0.39994982  1.0896416  -0.00987704  0.19683368  0.1987034   0.00666944]]\n",
      "학습 횟수 :  619 theta값 :  [[-0.40021977  1.08999294 -0.00985515  0.19603254  0.19836689  0.00667526]]\n",
      "학습 횟수 :  620 theta값 :  [[-0.40048831  1.09034437 -0.00983337  0.19523315  0.19803121  0.00668108]]\n",
      "학습 횟수 :  621 theta값 :  [[-0.40075545  1.09069588 -0.0098117   0.19443551  0.19769635  0.0066869 ]]\n",
      "학습 횟수 :  622 theta값 :  [[-0.40102118  1.09104747 -0.00979015  0.19363962  0.19736233  0.00669272]]\n",
      "학습 횟수 :  623 theta값 :  [[-0.40128552  1.09139914 -0.0097687   0.19284547  0.19702912  0.00669854]]\n",
      "학습 횟수 :  624 theta값 :  [[-0.40154846  1.09175089 -0.00974737  0.19205305  0.19669674  0.00670436]]\n",
      "학습 횟수 :  625 theta값 :  [[-0.40181001  1.09210272 -0.00972614  0.19126238  0.19636519  0.00671018]]\n",
      "학습 횟수 :  626 theta값 :  [[-0.40207018  1.09245462 -0.00970503  0.19047343  0.19603445  0.00671601]]\n",
      "학습 횟수 :  627 theta값 :  [[-0.40232897  1.09280661 -0.00968403  0.18968623  0.19570453  0.00672183]]\n",
      "학습 횟수 :  628 theta값 :  [[-0.40258638  1.09315867 -0.00966314  0.18890075  0.19537542  0.00672765]]\n",
      "학습 횟수 :  629 theta값 :  [[-0.40284243  1.09351081 -0.00964235  0.188117    0.19504713  0.00673347]]\n",
      "학습 횟수 :  630 theta값 :  [[-0.4030971   1.09386302 -0.00962168  0.18733497  0.19471965  0.00673929]]\n",
      "학습 횟수 :  631 theta값 :  [[-0.40335042  1.09421531 -0.00960111  0.18655467  0.19439298  0.00674511]]\n",
      "학습 횟수 :  632 theta값 :  [[-0.40360238  1.09456768 -0.00958065  0.18577609  0.19406712  0.00675093]]\n",
      "학습 횟수 :  633 theta값 :  [[-0.40385299  1.09492012 -0.0095603   0.18499922  0.19374207  0.00675675]]\n",
      "학습 횟수 :  634 theta값 :  [[-0.40410226  1.09527263 -0.00954005  0.18422407  0.19341782  0.00676257]]\n",
      "학습 횟수 :  635 theta값 :  [[-0.40435018  1.09562522 -0.00951992  0.18345064  0.19309437  0.00676839]]\n",
      "학습 횟수 :  636 theta값 :  [[-0.40459677  1.09597788 -0.00949989  0.18267891  0.19277172  0.00677421]]\n",
      "학습 횟수 :  637 theta값 :  [[-0.40484202  1.09633062 -0.00947996  0.18190889  0.19244987  0.00678002]]\n",
      "학습 횟수 :  638 theta값 :  [[-0.40508594  1.09668342 -0.00946014  0.18114057  0.19212882  0.00678584]]\n",
      "학습 횟수 :  639 theta값 :  [[-0.40532854  1.0970363  -0.00944043  0.18037396  0.19180857  0.00679165]]\n",
      "학습 횟수 :  640 theta값 :  [[-0.40556982  1.09738925 -0.00942082  0.17960905  0.1914891   0.00679747]]\n",
      "학습 횟수 :  641 theta값 :  [[-0.40580979  1.09774227 -0.00940132  0.17884583  0.19117043  0.00680328]]\n",
      "학습 횟수 :  642 theta값 :  [[-0.40604844  1.09809536 -0.00938192  0.17808431  0.19085255  0.00680909]]\n",
      "학습 횟수 :  643 theta값 :  [[-0.4062858   1.09844852 -0.00936263  0.17732447  0.19053545  0.0068149 ]]\n",
      "학습 횟수 :  644 theta값 :  [[-0.40652185  1.09880175 -0.00934344  0.17656633  0.19021915  0.00682071]]\n",
      "학습 횟수 :  645 theta값 :  [[-0.4067566   1.09915504 -0.00932435  0.17580987  0.18990362  0.00682651]]\n",
      "학습 횟수 :  646 theta값 :  [[-0.40699007  1.09950841 -0.00930536  0.1750551   0.18958888  0.00683232]]\n",
      "학습 횟수 :  647 theta값 :  [[-0.40722224  1.09986184 -0.00928648  0.17430201  0.18927491  0.00683812]]\n",
      "학습 횟수 :  648 theta값 :  [[-0.40745314  1.10021534 -0.0092677   0.17355059  0.18896173  0.00684392]]\n",
      "학습 횟수 :  649 theta값 :  [[-0.40768275  1.10056891 -0.00924903  0.17280085  0.18864932  0.00684972]]\n",
      "학습 횟수 :  650 theta값 :  [[-0.4079111   1.10092254 -0.00923045  0.17205278  0.18833768  0.00685552]]\n",
      "학습 횟수 :  651 theta값 :  [[-0.40813817  1.10127624 -0.00921198  0.17130638  0.18802682  0.00686131]]\n",
      "학습 횟수 :  652 theta값 :  [[-0.40836398  1.10163    -0.00919361  0.17056165  0.18771672  0.00686711]]\n",
      "학습 횟수 :  653 theta값 :  [[-0.40858854  1.10198383 -0.00917533  0.16981858  0.1874074   0.0068729 ]]\n",
      "학습 횟수 :  654 theta값 :  [[-0.40881183  1.10233772 -0.00915716  0.16907717  0.18709884  0.00687869]]\n",
      "학습 횟수 :  655 theta값 :  [[-0.40903388  1.10269168 -0.00913909  0.16833742  0.18679105  0.00688447]]\n",
      "학습 횟수 :  656 theta값 :  [[-0.40925468  1.1030457  -0.00912112  0.16759932  0.18648402  0.00689026]]\n",
      "학습 횟수 :  657 theta값 :  [[-0.40947424  1.10339978 -0.00910324  0.16686288  0.18617775  0.00689604]]\n",
      "학습 횟수 :  658 theta값 :  [[-0.40969256  1.10375393 -0.00908547  0.16612808  0.18587224  0.00690182]]\n",
      "학습 횟수 :  659 theta값 :  [[-0.40990965  1.10410813 -0.00906779  0.16539493  0.18556748  0.00690759]]\n",
      "학습 횟수 :  660 theta값 :  [[-0.41012551  1.1044624  -0.00905022  0.16466343  0.18526348  0.00691337]]\n",
      "학습 횟수 :  661 theta값 :  [[-0.41034015  1.10481673 -0.00903274  0.16393356  0.18496024  0.00691914]]\n",
      "학습 횟수 :  662 theta값 :  [[-0.41055357  1.10517111 -0.00901535  0.16320534  0.18465774  0.0069249 ]]\n",
      "학습 횟수 :  663 theta값 :  [[-0.41076577  1.10552556 -0.00899807  0.16247874  0.184356    0.00693067]]\n",
      "학습 횟수 :  664 theta값 :  [[-0.41097677  1.10588007 -0.00898088  0.16175378  0.184055    0.00693643]]\n",
      "학습 횟수 :  665 theta값 :  [[-0.41118656  1.10623464 -0.00896379  0.16103045  0.18375475  0.00694219]]\n",
      "학습 횟수 :  666 theta값 :  [[-0.41139514  1.10658926 -0.00894679  0.16030874  0.18345524  0.00694794]]\n",
      "학습 횟수 :  667 theta값 :  [[-0.41160253  1.10694394 -0.00892989  0.15958866  0.18315648  0.0069537 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  668 theta값 :  [[-0.41180873  1.10729868 -0.00891309  0.15887019  0.18285845  0.00695944]]\n",
      "학습 횟수 :  669 theta값 :  [[-0.41201374  1.10765348 -0.00889638  0.15815334  0.18256116  0.00696519]]\n",
      "학습 횟수 :  670 theta값 :  [[-0.41221757  1.10800833 -0.00887977  0.15743811  0.18226461  0.00697093]]\n",
      "학습 횟수 :  671 theta값 :  [[-0.41242022  1.10836324 -0.00886325  0.15672448  0.18196879  0.00697667]]\n",
      "학습 횟수 :  672 theta값 :  [[-0.41262169  1.1087182  -0.00884682  0.15601246  0.1816737   0.0069824 ]]\n",
      "학습 횟수 :  673 theta값 :  [[-0.41282199  1.10907322 -0.00883049  0.15530205  0.18137935  0.00698813]]\n",
      "학습 횟수 :  674 theta값 :  [[-0.41302113  1.10942829 -0.00881425  0.15459324  0.18108572  0.00699386]]\n",
      "학습 횟수 :  675 theta값 :  [[-0.41321911  1.10978342 -0.00879811  0.15388602  0.18079282  0.00699959]]\n",
      "학습 횟수 :  676 theta값 :  [[-0.41341593  1.1101386  -0.00878205  0.1531804   0.18050064  0.00700531]]\n",
      "학습 횟수 :  677 theta값 :  [[-0.41361159  1.11049383 -0.00876609  0.15247637  0.18020919  0.00701102]]\n",
      "학습 횟수 :  678 theta값 :  [[-0.41380611  1.11084912 -0.00875023  0.15177393  0.17991846  0.00701673]]\n",
      "학습 횟수 :  679 theta값 :  [[-0.41399948  1.11120446 -0.00873445  0.15107308  0.17962844  0.00702244]]\n",
      "학습 횟수 :  680 theta값 :  [[-0.41419171  1.11155985 -0.00871876  0.15037381  0.17933915  0.00702814]]\n",
      "학습 횟수 :  681 theta값 :  [[-0.41438281  1.11191529 -0.00870317  0.14967612  0.17905056  0.00703384]]\n",
      "학습 횟수 :  682 theta값 :  [[-0.41457278  1.11227078 -0.00868767  0.14898     0.17876269  0.00703954]]\n",
      "학습 횟수 :  683 theta값 :  [[-0.41476162  1.11262632 -0.00867226  0.14828546  0.17847554  0.00704523]]\n",
      "학습 횟수 :  684 theta값 :  [[-0.41494933  1.11298191 -0.00865693  0.14759249  0.17818909  0.00705092]]\n",
      "학습 횟수 :  685 theta값 :  [[-0.41513593  1.11333755 -0.0086417   0.14690108  0.17790335  0.0070566 ]]\n",
      "학습 횟수 :  686 theta값 :  [[-0.41532141  1.11369324 -0.00862656  0.14621124  0.17761831  0.00706228]]\n",
      "학습 횟수 :  687 theta값 :  [[-0.41550579  1.11404898 -0.0086115   0.14552296  0.17733398  0.00706795]]\n",
      "학습 횟수 :  688 theta값 :  [[-0.41568906  1.11440477 -0.00859654  0.14483623  0.17705035  0.00707362]]\n",
      "학습 횟수 :  689 theta값 :  [[-0.41587123  1.1147606  -0.00858166  0.14415106  0.17676742  0.00707928]]\n",
      "학습 횟수 :  690 theta값 :  [[-0.4160523   1.11511648 -0.00856688  0.14346744  0.17648519  0.00708494]]\n",
      "학습 횟수 :  691 theta값 :  [[-0.41623227  1.11547241 -0.00855217  0.14278537  0.17620365  0.00709059]]\n",
      "학습 횟수 :  692 theta값 :  [[-0.41641116  1.11582838 -0.00853756  0.14210484  0.17592281  0.00709624]]\n",
      "학습 횟수 :  693 theta값 :  [[-0.41658897  1.1161844  -0.00852304  0.14142585  0.17564266  0.00710189]]\n",
      "학습 횟수 :  694 theta값 :  [[-0.41676569  1.11654046 -0.0085086   0.1407484   0.1753632   0.00710753]]\n",
      "학습 횟수 :  695 theta값 :  [[-0.41694134  1.11689657 -0.00849424  0.14007248  0.17508443  0.00711316]]\n",
      "학습 횟수 :  696 theta값 :  [[-0.41711592  1.11725272 -0.00847998  0.1393981   0.17480635  0.00711879]]\n",
      "학습 횟수 :  697 theta값 :  [[-0.41728943  1.11760892 -0.0084658   0.13872524  0.17452895  0.00712442]]\n",
      "학습 횟수 :  698 theta값 :  [[-0.41746188  1.11796516 -0.0084517   0.13805391  0.17425223  0.00713004]]\n",
      "학습 횟수 :  699 theta값 :  [[-0.41763326  1.11832144 -0.00843769  0.1373841   0.1739762   0.00713565]]\n",
      "학습 횟수 :  700 theta값 :  [[-0.41780359  1.11867777 -0.00842377  0.13671581  0.17370084  0.00714126]]\n",
      "학습 횟수 :  701 theta값 :  [[-0.41797288  1.11903413 -0.00840993  0.13604903  0.17342616  0.00714686]]\n",
      "학습 횟수 :  702 theta값 :  [[-0.41814111  1.11939054 -0.00839617  0.13538377  0.17315216  0.00715246]]\n",
      "학습 횟수 :  703 theta값 :  [[-0.4183083   1.11974699 -0.0083825   0.13472001  0.17287883  0.00715805]]\n",
      "학습 횟수 :  704 theta값 :  [[-0.41847445  1.12010348 -0.00836891  0.13405776  0.17260617  0.00716364]]\n",
      "학습 횟수 :  705 theta값 :  [[-0.41863957  1.12046001 -0.00835541  0.13339701  0.17233418  0.00716922]]\n",
      "학습 횟수 :  706 theta값 :  [[-0.41880366  1.12081658 -0.00834199  0.13273776  0.17206286  0.0071748 ]]\n",
      "학습 횟수 :  707 theta값 :  [[-0.41896672  1.12117319 -0.00832865  0.13208     0.1717922   0.00718037]]\n",
      "학습 횟수 :  708 theta값 :  [[-0.41912876  1.12152984 -0.00831539  0.13142373  0.17152221  0.00718594]]\n",
      "학습 횟수 :  709 theta값 :  [[-0.41928978  1.12188653 -0.00830222  0.13076896  0.17125288  0.0071915 ]]\n",
      "학습 횟수 :  710 theta값 :  [[-0.41944979  1.12224325 -0.00828913  0.13011567  0.17098421  0.00719705]]\n",
      "학습 횟수 :  711 theta값 :  [[-0.41960879  1.12260001 -0.00827612  0.12946386  0.1707162   0.0072026 ]]\n",
      "학습 횟수 :  712 theta값 :  [[-0.41976678  1.12295681 -0.00826319  0.12881353  0.17044885  0.00720814]]\n",
      "학습 횟수 :  713 theta값 :  [[-0.41992377  1.12331365 -0.00825034  0.12816467  0.17018215  0.00721368]]\n",
      "학습 횟수 :  714 theta값 :  [[-0.42007976  1.12367052 -0.00823757  0.12751729  0.16991611  0.00721921]]\n",
      "학습 횟수 :  715 theta값 :  [[-0.42023476  1.12402743 -0.00822488  0.12687137  0.16965071  0.00722473]]\n",
      "학습 횟수 :  716 theta값 :  [[-0.42038876  1.12438437 -0.00821227  0.12622692  0.16938597  0.00723025]]\n",
      "학습 횟수 :  717 theta값 :  [[-0.42054178  1.12474135 -0.00819974  0.12558393  0.16912187  0.00723577]]\n",
      "학습 횟수 :  718 theta값 :  [[-0.42069382  1.12509836 -0.00818729  0.1249424   0.16885842  0.00724127]]\n",
      "학습 횟수 :  719 theta값 :  [[-0.42084489  1.12545541 -0.00817492  0.12430233  0.16859561  0.00724677]]\n",
      "학습 횟수 :  720 theta값 :  [[-0.42099497  1.12581249 -0.00816263  0.12366371  0.16833344  0.00725227]]\n",
      "학습 횟수 :  721 theta값 :  [[-0.42114409  1.12616961 -0.00815042  0.12302653  0.16807191  0.00725776]]\n",
      "학습 횟수 :  722 theta값 :  [[-0.42129224  1.12652675 -0.00813828  0.1223908   0.16781103  0.00726324]]\n",
      "학습 횟수 :  723 theta값 :  [[-0.42143943  1.12688393 -0.00812623  0.12175652  0.16755077  0.00726871]]\n",
      "학습 횟수 :  724 theta값 :  [[-0.42158566  1.12724114 -0.00811425  0.12112367  0.16729116  0.00727418]]\n",
      "학습 횟수 :  725 theta값 :  [[-0.42173093  1.12759839 -0.00810234  0.12049225  0.16703217  0.00727965]]\n",
      "학습 횟수 :  726 theta값 :  [[-0.42187526  1.12795566 -0.00809052  0.11986227  0.16677382  0.0072851 ]]\n",
      "학습 횟수 :  727 theta값 :  [[-0.42201864  1.12831296 -0.00807877  0.11923372  0.16651609  0.00729055]]\n",
      "학습 횟수 :  728 theta값 :  [[-0.42216107  1.1286703  -0.00806709  0.11860659  0.16625899  0.007296  ]]\n",
      "학습 횟수 :  729 theta값 :  [[-0.42230257  1.12902766 -0.0080555   0.11798088  0.16600252  0.00730144]]\n",
      "학습 횟수 :  730 theta값 :  [[-0.42244313  1.12938506 -0.00804398  0.11735659  0.16574667  0.00730687]]\n",
      "학습 횟수 :  731 theta값 :  [[-0.42258276  1.12974248 -0.00803253  0.11673372  0.16549145  0.00731229]]\n",
      "학습 횟수 :  732 theta값 :  [[-0.42272147  1.13009993 -0.00802116  0.11611225  0.16523684  0.00731771]]\n",
      "학습 횟수 :  733 theta값 :  [[-0.42285925  1.13045741 -0.00800986  0.1154922   0.16498285  0.00732312]]\n",
      "학습 횟수 :  734 theta값 :  [[-0.42299611  1.13081492 -0.00799864  0.11487355  0.16472948  0.00732853]]\n",
      "학습 횟수 :  735 theta값 :  [[-0.42313205  1.13117246 -0.00798749  0.1142563   0.16447672  0.00733392]]\n",
      "학습 횟수 :  736 theta값 :  [[-0.42326708  1.13153002 -0.00797642  0.11364045  0.16422458  0.00733932]]\n",
      "학습 횟수 :  737 theta값 :  [[-0.4234012   1.13188761 -0.00796542  0.11302599  0.16397304  0.0073447 ]]\n",
      "학습 횟수 :  738 theta값 :  [[-0.42353442  1.13224522 -0.00795449  0.11241293  0.16372212  0.00735008]]\n",
      "학습 횟수 :  739 theta값 :  [[-0.42366674  1.13260286 -0.00794364  0.11180125  0.1634718   0.00735545]]\n",
      "학습 횟수 :  740 theta값 :  [[-0.42379816  1.13296053 -0.00793286  0.11119096  0.16322209  0.00736081]]\n",
      "학습 횟수 :  741 theta값 :  [[-0.42392869  1.13331822 -0.00792215  0.11058204  0.16297298  0.00736617]]\n",
      "학습 횟수 :  742 theta값 :  [[-0.42405833  1.13367593 -0.00791151  0.10997451  0.16272447  0.00737152]]\n",
      "학습 횟수 :  743 theta값 :  [[-0.42418708  1.13403367 -0.00790095  0.10936835  0.16247657  0.00737686]]\n",
      "학습 횟수 :  744 theta값 :  [[-0.42431495  1.13439144 -0.00789046  0.10876356  0.16222926  0.0073822 ]]\n",
      "학습 횟수 :  745 theta값 :  [[-0.42444194  1.13474922 -0.00788004  0.10816014  0.16198255  0.00738753]]\n",
      "학습 횟수 :  746 theta값 :  [[-0.42456805  1.13510703 -0.00786969  0.10755808  0.16173644  0.00739285]]\n",
      "학습 횟수 :  747 theta값 :  [[-0.4246933   1.13546486 -0.00785941  0.10695738  0.16149091  0.00739817]]\n",
      "학습 횟수 :  748 theta값 :  [[-0.42481768  1.13582272 -0.0078492   0.10635805  0.16124598  0.00740348]]\n",
      "학습 횟수 :  749 theta값 :  [[-0.42494119  1.13618059 -0.00783906  0.10576006  0.16100164  0.00740878]]\n",
      "학습 횟수 :  750 theta값 :  [[-0.42506385  1.13653849 -0.00782899  0.10516343  0.16075789  0.00741407]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  751 theta값 :  [[-0.42518564  1.13689641 -0.00781899  0.10456814  0.16051472  0.00741936]]\n",
      "학습 횟수 :  752 theta값 :  [[-0.42530659  1.13725434 -0.00780906  0.1039742   0.16027214  0.00742464]]\n",
      "학습 횟수 :  753 theta값 :  [[-0.42542668  1.1376123  -0.0077992   0.10338159  0.16003014  0.00742991]]\n",
      "학습 횟수 :  754 theta값 :  [[-0.42554593  1.13797028 -0.00778941  0.10279033  0.15978872  0.00743518]]\n",
      "학습 횟수 :  755 theta값 :  [[-0.42566434  1.13832828 -0.00777968  0.1022004   0.15954788  0.00744044]]\n",
      "학습 횟수 :  756 theta값 :  [[-0.42578191  1.1386863  -0.00777003  0.10161179  0.15930762  0.00744569]]\n",
      "학습 횟수 :  757 theta값 :  [[-0.42589864  1.13904433 -0.00776044  0.10102452  0.15906793  0.00745093]]\n",
      "학습 횟수 :  758 theta값 :  [[-0.42601454  1.13940238 -0.00775092  0.10043857  0.15882882  0.00745617]]\n",
      "학습 횟수 :  759 theta값 :  [[-0.42612962  1.13976045 -0.00774146  0.09985394  0.15859028  0.0074614 ]]\n",
      "학습 횟수 :  760 theta값 :  [[-0.42624387  1.14011854 -0.00773208  0.09927063  0.15835231  0.00746662]]\n",
      "학습 횟수 :  761 theta값 :  [[-0.4263573   1.14047665 -0.00772276  0.09868863  0.15811491  0.00747184]]\n",
      "학습 횟수 :  762 theta값 :  [[-0.42646991  1.14083477 -0.00771351  0.09810794  0.15787808  0.00747704]]\n",
      "학습 횟수 :  763 theta값 :  [[-0.42658171  1.14119291 -0.00770432  0.09752856  0.15764181  0.00748224]]\n",
      "학습 횟수 :  764 theta값 :  [[-0.4266927   1.14155106 -0.0076952   0.09695048  0.15740611  0.00748744]]\n",
      "학습 횟수 :  765 theta값 :  [[-0.42680288  1.14190923 -0.00768615  0.0963737   0.15717096  0.00749262]]\n",
      "학습 횟수 :  766 theta값 :  [[-0.42691226  1.14226742 -0.00767716  0.09579822  0.15693638  0.0074978 ]]\n",
      "학습 횟수 :  767 theta값 :  [[-0.42702084  1.14262562 -0.00766823  0.09522403  0.15670236  0.00750297]]\n",
      "학습 횟수 :  768 theta값 :  [[-0.42712862  1.14298383 -0.00765938  0.09465113  0.15646889  0.00750813]]\n",
      "학습 횟수 :  769 theta값 :  [[-0.42723561  1.14334206 -0.00765058  0.09407952  0.15623598  0.00751329]]\n",
      "학습 횟수 :  770 theta값 :  [[-0.42734181  1.1437003  -0.00764185  0.0935092   0.15600362  0.00751844]]\n",
      "학습 횟수 :  771 theta값 :  [[-0.42744722  1.14405856 -0.00763319  0.09294015  0.15577182  0.00752358]]\n",
      "학습 횟수 :  772 theta값 :  [[-0.42755186  1.14441682 -0.00762459  0.09237238  0.15554056  0.00752871]]\n",
      "학습 횟수 :  773 theta값 :  [[-0.42765571  1.1447751  -0.00761605  0.09180589  0.15530986  0.00753383]]\n",
      "학습 횟수 :  774 theta값 :  [[-0.42775878  1.1451334  -0.00760757  0.09124066  0.1550797   0.00753895]]\n",
      "학습 횟수 :  775 theta값 :  [[-0.42786109  1.1454917  -0.00759916  0.0906767   0.15485008  0.00754406]]\n",
      "학습 횟수 :  776 theta값 :  [[-0.42796262  1.14585002 -0.00759081  0.09011401  0.15462101  0.00754916]]\n",
      "학습 횟수 :  777 theta값 :  [[-0.42806339  1.14620834 -0.00758253  0.08955257  0.15439248  0.00755426]]\n",
      "학습 횟수 :  778 theta값 :  [[-0.4281634   1.14656668 -0.0075743   0.0889924   0.15416449  0.00755934]]\n",
      "학습 횟수 :  779 theta값 :  [[-0.42826265  1.14692503 -0.00756614  0.08843347  0.15393704  0.00756442]]\n",
      "학습 횟수 :  780 theta값 :  [[-0.42836114  1.14728338 -0.00755804  0.0878758   0.15371013  0.0075695 ]]\n",
      "학습 횟수 :  781 theta값 :  [[-0.42845888  1.14764175 -0.00755     0.08731937  0.15348375  0.00757456]]\n",
      "학습 횟수 :  782 theta값 :  [[-0.42855587  1.14800013 -0.00754202  0.08676419  0.1532579   0.00757962]]\n",
      "학습 횟수 :  783 theta값 :  [[-0.42865211  1.14835851 -0.00753411  0.08621025  0.15303259  0.00758466]]\n",
      "학습 횟수 :  784 theta값 :  [[-0.42874761  1.14871691 -0.00752625  0.08565755  0.15280781  0.0075897 ]]\n",
      "학습 횟수 :  785 theta값 :  [[-0.42884238  1.14907531 -0.00751845  0.08510607  0.15258355  0.00759474]]\n",
      "학습 횟수 :  786 theta값 :  [[-0.4289364   1.14943372 -0.00751072  0.08455584  0.15235983  0.00759976]]\n",
      "학습 횟수 :  787 theta값 :  [[-0.4290297   1.14979213 -0.00750304  0.08400682  0.15213663  0.00760478]]\n",
      "학습 횟수 :  788 theta값 :  [[-0.42912226  1.15015056 -0.00749543  0.08345904  0.15191395  0.00760979]]\n",
      "학습 횟수 :  789 theta값 :  [[-0.4292141   1.15050899 -0.00748787  0.08291247  0.15169179  0.00761479]]\n",
      "학습 횟수 :  790 theta값 :  [[-0.42930522  1.15086743 -0.00748038  0.08236712  0.15147016  0.00761979]]\n",
      "학습 횟수 :  791 theta값 :  [[-0.42939561  1.15122587 -0.00747294  0.08182298  0.15124904  0.00762477]]\n",
      "학습 횟수 :  792 theta값 :  [[-0.42948529  1.15158432 -0.00746556  0.08128006  0.15102845  0.00762975]]\n",
      "학습 횟수 :  793 theta값 :  [[-0.42957426  1.15194277 -0.00745824  0.08073835  0.15080836  0.00763472]]\n",
      "학습 횟수 :  794 theta값 :  [[-0.42966251  1.15230123 -0.00745098  0.08019783  0.1505888   0.00763968]]\n",
      "학습 횟수 :  795 theta값 :  [[-0.42975006  1.15265969 -0.00744377  0.07965853  0.15036974  0.00764464]]\n",
      "학습 횟수 :  796 theta값 :  [[-0.4298369   1.15301816 -0.00743663  0.07912041  0.1501512   0.00764959]]\n",
      "학습 횟수 :  797 theta값 :  [[-0.42992305  1.15337663 -0.00742954  0.0785835   0.14993316  0.00765453]]\n",
      "학습 횟수 :  798 theta값 :  [[-0.43000849  1.15373511 -0.0074225   0.07804777  0.14971564  0.00765946]]\n",
      "학습 횟수 :  799 theta값 :  [[-0.43009325  1.15409358 -0.00741553  0.07751324  0.14949861  0.00766438]]\n",
      "학습 횟수 :  800 theta값 :  [[-0.43017731  1.15445207 -0.00740861  0.07697989  0.1492821   0.0076693 ]]\n",
      "학습 횟수 :  801 theta값 :  [[-0.43026068  1.15481055 -0.00740175  0.07644772  0.14906609  0.0076742 ]]\n",
      "학습 횟수 :  802 theta값 :  [[-0.43034336  1.15516903 -0.00739494  0.07591673  0.14885058  0.0076791 ]]\n",
      "학습 횟수 :  803 theta값 :  [[-0.43042537  1.15552752 -0.0073882   0.07538692  0.14863556  0.007684  ]]\n",
      "학습 횟수 :  804 theta값 :  [[-0.43050669  1.15588601 -0.0073815   0.07485827  0.14842105  0.00768888]]\n",
      "학습 횟수 :  805 theta값 :  [[-0.43058734  1.1562445  -0.00737486  0.0743308   0.14820704  0.00769376]]\n",
      "학습 횟수 :  806 theta값 :  [[-0.43066732  1.15660299 -0.00736828  0.0738045   0.14799352  0.00769862]]\n",
      "학습 횟수 :  807 theta값 :  [[-0.43074663  1.15696148 -0.00736175  0.07327935  0.14778049  0.00770348]]\n",
      "학습 횟수 :  808 theta값 :  [[-0.43082526  1.15731998 -0.00735528  0.07275537  0.14756796  0.00770834]]\n",
      "학습 횟수 :  809 theta값 :  [[-0.43090324  1.15767847 -0.00734886  0.07223254  0.14735591  0.00771318]]\n",
      "학습 횟수 :  810 theta값 :  [[-0.43098056  1.15803696 -0.0073425   0.07171087  0.14714436  0.00771802]]\n",
      "학습 횟수 :  811 theta값 :  [[-0.43105721  1.15839545 -0.00733619  0.07119035  0.14693329  0.00772285]]\n",
      "학습 횟수 :  812 theta값 :  [[-0.43113322  1.15875394 -0.00732993  0.07067097  0.14672271  0.00772767]]\n",
      "학습 횟수 :  813 theta값 :  [[-0.43120857  1.15911242 -0.00732373  0.07015274  0.14651262  0.00773248]]\n",
      "학습 횟수 :  814 theta값 :  [[-0.43128327  1.15947091 -0.00731758  0.06963565  0.14630301  0.00773728]]\n",
      "학습 횟수 :  815 theta값 :  [[-0.43135732  1.15982939 -0.00731149  0.0691197   0.14609388  0.00774208]]\n",
      "학습 횟수 :  816 theta값 :  [[-0.43143074  1.16018787 -0.00730544  0.06860488  0.14588523  0.00774687]]\n",
      "학습 횟수 :  817 theta값 :  [[-0.43150351  1.16054635 -0.00729945  0.0680912   0.14567706  0.00775165]]\n",
      "학습 횟수 :  818 theta값 :  [[-0.43157564  1.16090483 -0.00729352  0.06757864  0.14546936  0.00775642]]\n",
      "학습 횟수 :  819 theta값 :  [[-0.43164715  1.1612633  -0.00728763  0.0670672   0.14526214  0.00776119]]\n",
      "학습 횟수 :  820 theta값 :  [[-0.43171802  1.16162177 -0.0072818   0.06655689  0.1450554   0.00776594]]\n",
      "학습 횟수 :  821 theta값 :  [[-0.43178826  1.16198023 -0.00727602  0.0660477   0.14484913  0.00777069]]\n",
      "학습 횟수 :  822 theta값 :  [[-0.43185787  1.16233869 -0.00727029  0.06553963  0.14464333  0.00777543]]\n",
      "학습 횟수 :  823 theta값 :  [[-0.43192687  1.16269714 -0.00726461  0.06503267  0.144438    0.00778017]]\n",
      "학습 횟수 :  824 theta값 :  [[-0.43199524  1.16305559 -0.00725898  0.06452681  0.14423313  0.00778489]]\n",
      "학습 횟수 :  825 theta값 :  [[-0.432063    1.16341404 -0.00725341  0.06402207  0.14402874  0.00778961]]\n",
      "학습 횟수 :  826 theta값 :  [[-0.43213014  1.16377247 -0.00724788  0.06351842  0.14382481  0.00779432]]\n",
      "학습 횟수 :  827 theta값 :  [[-0.43219667  1.16413091 -0.0072424   0.06301588  0.14362134  0.00779902]]\n",
      "학습 횟수 :  828 theta값 :  [[-0.43226259  1.16448933 -0.00723698  0.06251444  0.14341834  0.00780371]]\n",
      "학습 횟수 :  829 theta값 :  [[-0.43232791  1.16484775 -0.00723161  0.06201409  0.14321579  0.0078084 ]]\n",
      "학습 횟수 :  830 theta값 :  [[-0.43239263  1.16520616 -0.00722628  0.06151483  0.14301371  0.00781307]]\n",
      "학습 횟수 :  831 theta값 :  [[-0.43245674  1.16556457 -0.00722101  0.06101666  0.14281209  0.00781774]]\n",
      "학습 횟수 :  832 theta값 :  [[-0.43252026  1.16592296 -0.00721578  0.06051958  0.14261092  0.0078224 ]]\n",
      "학습 횟수 :  833 theta값 :  [[-0.43258318  1.16628135 -0.0072106   0.06002357  0.1424102   0.00782706]]\n",
      "학습 횟수 :  834 theta값 :  [[-0.43264552  1.16663974 -0.00720547  0.05952865  0.14220994  0.0078317 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  835 theta값 :  [[-0.43270726  1.16699811 -0.0072004   0.05903481  0.14201013  0.00783634]]\n",
      "학습 횟수 :  836 theta값 :  [[-0.43276841  1.16735647 -0.00719536  0.05854203  0.14181078  0.00784097]]\n",
      "학습 횟수 :  837 theta값 :  [[-0.43282899  1.16771483 -0.00719038  0.05805033  0.14161187  0.00784559]]\n",
      "학습 횟수 :  838 theta값 :  [[-0.43288898  1.16807317 -0.00718545  0.05755969  0.14141341  0.0078502 ]]\n",
      "학습 횟수 :  839 theta값 :  [[-0.4329484   1.16843151 -0.00718056  0.05707012  0.1412154   0.0078548 ]]\n",
      "학습 횟수 :  840 theta값 :  [[-0.43300723  1.16878983 -0.00717572  0.05658161  0.14101783  0.0078594 ]]\n",
      "학습 횟수 :  841 theta값 :  [[-0.4330655   1.16914815 -0.00717093  0.05609416  0.14082071  0.00786399]]\n",
      "학습 횟수 :  842 theta값 :  [[-0.4331232   1.16950645 -0.00716619  0.05560777  0.14062403  0.00786857]]\n",
      "학습 횟수 :  843 theta값 :  [[-0.43318033  1.16986474 -0.00716149  0.05512242  0.14042779  0.00787314]]\n",
      "학습 횟수 :  844 theta값 :  [[-0.43323689  1.17022303 -0.00715684  0.05463813  0.14023199  0.00787771]]\n",
      "학습 횟수 :  845 theta값 :  [[-0.4332929   1.1705813  -0.00715224  0.05415488  0.14003662  0.00788227]]\n",
      "학습 횟수 :  846 theta값 :  [[-0.43334834  1.17093956 -0.00714768  0.05367268  0.1398417   0.00788682]]\n",
      "학습 횟수 :  847 theta값 :  [[-0.43340323  1.1712978  -0.00714317  0.05319152  0.13964721  0.00789136]]\n",
      "학습 횟수 :  848 theta값 :  [[-0.43345756  1.17165604 -0.0071387   0.05271139  0.13945315  0.00789589]]\n",
      "학습 횟수 :  849 theta값 :  [[-0.43351134  1.17201426 -0.00713428  0.0522323   0.13925953  0.00790042]]\n",
      "학습 횟수 :  850 theta값 :  [[-0.43356458  1.17237247 -0.00712991  0.05175424  0.13906634  0.00790493]]\n",
      "학습 횟수 :  851 theta값 :  [[-0.43361726  1.17273066 -0.00712558  0.05127721  0.13887358  0.00790944]]\n",
      "학습 횟수 :  852 theta값 :  [[-0.43366941  1.17308884 -0.0071213   0.05080121  0.13868125  0.00791394]]\n",
      "학습 횟수 :  853 theta값 :  [[-0.43372101  1.17344701 -0.00711706  0.05032623  0.13848934  0.00791844]]\n",
      "학습 횟수 :  854 theta값 :  [[-0.43377208  1.17380516 -0.00711287  0.04985227  0.13829786  0.00792292]]\n",
      "학습 횟수 :  855 theta값 :  [[-0.4338226   1.1741633  -0.00710872  0.04937932  0.1381068   0.0079274 ]]\n",
      "학습 횟수 :  856 theta값 :  [[-0.4338726   1.17452143 -0.00710462  0.0489074   0.13791617  0.00793187]]\n",
      "학습 횟수 :  857 theta값 :  [[-0.43392207  1.17487954 -0.00710056  0.04843648  0.13772596  0.00793633]]\n",
      "학습 횟수 :  858 theta값 :  [[-0.433971    1.17523763 -0.00709654  0.04796657  0.13753617  0.00794078]]\n",
      "학습 횟수 :  859 theta값 :  [[-0.43401941  1.17559571 -0.00709257  0.04749767  0.1373468   0.00794523]]\n",
      "학습 횟수 :  860 theta값 :  [[-0.4340673   1.17595377 -0.00708864  0.04702977  0.13715785  0.00794967]]\n",
      "학습 횟수 :  861 theta값 :  [[-0.43411467  1.17631182 -0.00708475  0.04656287  0.13696932  0.0079541 ]]\n",
      "학습 횟수 :  862 theta값 :  [[-0.43416152  1.17666985 -0.00708091  0.04609697  0.1367812   0.00795852]]\n",
      "학습 횟수 :  863 theta값 :  [[-0.43420785  1.17702786 -0.00707711  0.04563207  0.13659349  0.00796293]]\n",
      "학습 횟수 :  864 theta값 :  [[-0.43425367  1.17738585 -0.00707335  0.04516815  0.1364062   0.00796734]]\n",
      "학습 횟수 :  865 theta값 :  [[-0.43429898  1.17774383 -0.00706964  0.04470523  0.13621931  0.00797174]]\n",
      "학습 횟수 :  866 theta값 :  [[-0.43434378  1.17810179 -0.00706597  0.04424329  0.13603284  0.00797613]]\n",
      "학습 횟수 :  867 theta값 :  [[-0.43438807  1.17845974 -0.00706234  0.04378233  0.13584678  0.00798051]]\n",
      "학습 횟수 :  868 theta값 :  [[-0.43443187  1.17881766 -0.00705875  0.04332236  0.13566112  0.00798489]]\n",
      "학습 횟수 :  869 theta값 :  [[-0.43447516  1.17917557 -0.0070552   0.04286336  0.13547587  0.00798925]]\n",
      "학습 횟수 :  870 theta값 :  [[-0.43451795  1.17953345 -0.0070517   0.04240534  0.13529103  0.00799361]]\n",
      "학습 횟수 :  871 theta값 :  [[-0.43456024  1.17989132 -0.00704824  0.04194829  0.13510658  0.00799796]]\n",
      "학습 횟수 :  872 theta값 :  [[-0.43460205  1.18024917 -0.00704482  0.04149221  0.13492255  0.00800231]]\n",
      "학습 횟수 :  873 theta값 :  [[-0.43464336  1.180607   -0.00704144  0.04103709  0.13473891  0.00800664]]\n",
      "학습 횟수 :  874 theta값 :  [[-0.43468418  1.18096481 -0.0070381   0.04058294  0.13455567  0.00801097]]\n",
      "학습 횟수 :  875 theta값 :  [[-0.43472451  1.1813226  -0.0070348   0.04012975  0.13437283  0.00801529]]\n",
      "학습 횟수 :  876 theta값 :  [[-0.43476437  1.18168037 -0.00703154  0.03967752  0.13419039  0.0080196 ]]\n",
      "학습 횟수 :  877 theta값 :  [[-0.43480373  1.18203812 -0.00702832  0.03922625  0.13400834  0.00802391]]\n",
      "학습 횟수 :  878 theta값 :  [[-0.43484262  1.18239585 -0.00702515  0.03877593  0.13382669  0.0080282 ]]\n",
      "학습 횟수 :  879 theta값 :  [[-0.43488104  1.18275355 -0.00702201  0.03832656  0.13364543  0.00803249]]\n",
      "학습 횟수 :  880 theta값 :  [[-0.43491897  1.18311124 -0.00701891  0.03787813  0.13346456  0.00803677]]\n",
      "학습 횟수 :  881 theta값 :  [[-0.43495644  1.1834689  -0.00701585  0.03743065  0.13328409  0.00804104]]\n",
      "학습 횟수 :  882 theta값 :  [[-0.43499343  1.18382655 -0.00701283  0.03698412  0.133104    0.00804531]]\n",
      "학습 횟수 :  883 theta값 :  [[-0.43502996  1.18418417 -0.00700985  0.03653852  0.1329243   0.00804957]]\n",
      "학습 횟수 :  884 theta값 :  [[-0.43506602  1.18454176 -0.00700691  0.03609386  0.13274499  0.00805382]]\n",
      "학습 횟수 :  885 theta값 :  [[-0.43510162  1.18489934 -0.00700401  0.03565013  0.13256607  0.00805806]]\n",
      "학습 횟수 :  886 theta값 :  [[-0.43513676  1.18525689 -0.00700115  0.03520734  0.13238753  0.00806229]]\n",
      "학습 횟수 :  887 theta값 :  [[-0.43517144  1.18561442 -0.00699832  0.03476547  0.13220938  0.00806652]]\n",
      "학습 횟수 :  888 theta값 :  [[-0.43520566  1.18597192 -0.00699554  0.03432454  0.1320316   0.00807074]]\n",
      "학습 횟수 :  889 theta값 :  [[-0.43523943  1.1863294  -0.00699279  0.03388452  0.13185421  0.00807495]]\n",
      "학습 횟수 :  890 theta값 :  [[-0.43527274  1.18668686 -0.00699008  0.03344542  0.1316772   0.00807915]]\n",
      "학습 횟수 :  891 theta값 :  [[-0.43530561  1.18704429 -0.0069874   0.03300725  0.13150056  0.00808335]]\n",
      "학습 횟수 :  892 theta값 :  [[-0.43533802  1.1874017  -0.00698477  0.03256999  0.13132431  0.00808754]]\n",
      "학습 횟수 :  893 theta값 :  [[-0.43537     1.18775908 -0.00698217  0.03213364  0.13114843  0.00809172]]\n",
      "학습 횟수 :  894 theta값 :  [[-0.43540153  1.18811644 -0.00697961  0.0316982   0.13097293  0.00809589]]\n",
      "학습 횟수 :  895 theta값 :  [[-0.43543261  1.18847378 -0.00697709  0.03126367  0.1307978   0.00810005]]\n",
      "학습 횟수 :  896 theta값 :  [[-0.43546326  1.18883108 -0.0069746   0.03083005  0.13062304  0.00810421]]\n",
      "학습 횟수 :  897 theta값 :  [[-0.43549348  1.18918837 -0.00697215  0.03039733  0.13044865  0.00810836]]\n",
      "학습 횟수 :  898 theta값 :  [[-0.43552325  1.18954562 -0.00696974  0.02996551  0.13027464  0.0081125 ]]\n",
      "학습 횟수 :  899 theta값 :  [[-0.4355526   1.18990285 -0.00696736  0.02953458  0.13010099  0.00811664]]\n",
      "학습 횟수 :  900 theta값 :  [[-0.43558152  1.19026005 -0.00696502  0.02910455  0.12992771  0.00812076]]\n",
      "학습 횟수 :  901 theta값 :  [[-0.43561     1.19061723 -0.00696272  0.02867542  0.1297548   0.00812488]]\n",
      "학습 횟수 :  902 theta값 :  [[-0.43563807  1.19097438 -0.00696045  0.02824717  0.12958226  0.00812899]]\n",
      "학습 횟수 :  903 theta값 :  [[-0.4356657   1.1913315  -0.00695822  0.02781981  0.12941007  0.0081331 ]]\n",
      "학습 횟수 :  904 theta값 :  [[-0.43569292  1.1916886  -0.00695602  0.02739333  0.12923826  0.0081372 ]]\n",
      "학습 횟수 :  905 theta값 :  [[-0.43571972  1.19204566 -0.00695386  0.02696774  0.1290668   0.00814128]]\n",
      "학습 횟수 :  906 theta값 :  [[-0.4357461   1.1924027  -0.00695173  0.02654303  0.12889571  0.00814537]]\n",
      "학습 횟수 :  907 theta값 :  [[-0.43577206  1.19275971 -0.00694964  0.02611919  0.12872497  0.00814944]]\n",
      "학습 횟수 :  908 theta값 :  [[-0.43579761  1.19311669 -0.00694759  0.02569623  0.1285546   0.00815351]]\n",
      "학습 횟수 :  909 theta값 :  [[-0.43582275  1.19347365 -0.00694557  0.02527414  0.12838458  0.00815756]]\n",
      "학습 횟수 :  910 theta값 :  [[-0.43584749  1.19383057 -0.00694358  0.02485292  0.12821492  0.00816162]]\n",
      "학습 횟수 :  911 theta값 :  [[-0.43587181  1.19418747 -0.00694163  0.02443257  0.12804561  0.00816566]]\n",
      "학습 횟수 :  912 theta값 :  [[-0.43589573  1.19454433 -0.00693971  0.02401308  0.12787666  0.00816969]]\n",
      "학습 횟수 :  913 theta값 :  [[-0.43591925  1.19490117 -0.00693782  0.02359446  0.12770806  0.00817372]]\n",
      "학습 횟수 :  914 theta값 :  [[-0.43594236  1.19525797 -0.00693597  0.02317669  0.12753982  0.00817774]]\n",
      "학습 횟수 :  915 theta값 :  [[-0.43596508  1.19561475 -0.00693416  0.02275979  0.12737192  0.00818176]]\n",
      "학습 횟수 :  916 theta값 :  [[-0.4359874   1.19597149 -0.00693237  0.02234373  0.12720438  0.00818576]]\n",
      "학습 횟수 :  917 theta값 :  [[-0.43600932  1.19632821 -0.00693063  0.02192853  0.12703718  0.00818976]]\n",
      "학습 횟수 :  918 theta값 :  [[-0.43603086  1.19668489 -0.00692891  0.02151418  0.12687033  0.00819375]]\n",
      "학습 횟수 :  919 theta값 :  [[-0.436052    1.19704155 -0.00692723  0.02110068  0.12670383  0.00819774]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 횟수 :  920 theta값 :  [[-0.43607275  1.19739817 -0.00692558  0.02068802  0.12653768  0.00820171]]\n",
      "학습 횟수 :  921 theta값 :  [[-0.43609312  1.19775476 -0.00692396  0.0202762   0.12637186  0.00820568]]\n",
      "학습 횟수 :  922 theta값 :  [[-0.4361131   1.19811132 -0.00692237  0.01986523  0.12620639  0.00820965]]\n",
      "학습 횟수 :  923 theta값 :  [[-0.43613269  1.19846784 -0.00692082  0.01945509  0.12604127  0.0082136 ]]\n",
      "학습 횟수 :  924 theta값 :  [[-0.43615191  1.19882434 -0.0069193   0.01904579  0.12587648  0.00821755]]\n",
      "학습 횟수 :  925 theta값 :  [[-0.43617075  1.1991808  -0.00691782  0.01863732  0.12571204  0.00822149]]\n",
      "학습 횟수 :  926 theta값 :  [[-0.43618921  1.19953723 -0.00691636  0.01822968  0.12554793  0.00822542]]\n",
      "학습 횟수 :  927 theta값 :  [[-0.4362073   1.19989362 -0.00691494  0.01782287  0.12538416  0.00822934]]\n",
      "학습 횟수 :  928 theta값 :  [[-0.43622501  1.20024999 -0.00691355  0.01741689  0.12522073  0.00823326]]\n",
      "학습 횟수 :  929 theta값 :  [[-0.43624235  1.20060632 -0.00691219  0.01701173  0.12505763  0.00823717]]\n",
      "학습 횟수 :  930 theta값 :  [[-0.43625932  1.20096261 -0.00691086  0.01660739  0.12489487  0.00824107]]\n",
      "학습 횟수 :  931 theta값 :  [[-0.43627593  1.20131887 -0.00690956  0.01620387  0.12473244  0.00824497]]\n",
      "학습 횟수 :  932 theta값 :  [[-0.43629217  1.2016751  -0.00690829  0.01580117  0.12457035  0.00824886]]\n",
      "학습 횟수 :  933 theta값 :  [[-0.43630804  1.2020313  -0.00690706  0.01539928  0.12440858  0.00825274]]\n",
      "학습 횟수 :  934 theta값 :  [[-0.43632356  1.20238746 -0.00690585  0.0149982   0.12424715  0.00825661]]\n",
      "학습 횟수 :  935 theta값 :  [[-0.43633871  1.20274358 -0.00690468  0.01459793  0.12408605  0.00826048]]\n",
      "학습 횟수 :  936 theta값 :  [[-0.43635351  1.20309967 -0.00690354  0.01419847  0.12392527  0.00826434]]\n",
      "학습 횟수 :  937 theta값 :  [[-0.43636795  1.20345573 -0.00690242  0.01379982  0.12376482  0.00826819]]\n",
      "학습 횟수 :  938 theta값 :  [[-0.43638203  1.20381175 -0.00690134  0.01340197  0.1236047   0.00827204]]\n",
      "학습 횟수 :  939 theta값 :  [[-0.43639576  1.20416773 -0.00690029  0.01300491  0.12344491  0.00827587]]\n",
      "학습 횟수 :  940 theta값 :  [[-0.43640915  1.20452368 -0.00689927  0.01260866  0.12328543  0.0082797 ]]\n",
      "학습 횟수 :  941 theta값 :  [[-0.43642218  1.20487959 -0.00689827  0.0122132   0.12312628  0.00828353]]\n",
      "학습 횟수 :  942 theta값 :  [[-0.43643487  1.20523547 -0.00689731  0.01181854  0.12296746  0.00828734]]\n",
      "학습 횟수 :  943 theta값 :  [[-0.43644721  1.20559131 -0.00689638  0.01142466  0.12280895  0.00829115]]\n",
      "학습 횟수 :  944 theta값 :  [[-0.4364592   1.20594711 -0.00689547  0.01103158  0.12265077  0.00829496]]\n",
      "학습 횟수 :  945 theta값 :  [[-0.43647086  1.20630288 -0.0068946   0.01063928  0.1224929   0.00829875]]\n",
      "학습 횟수 :  946 theta값 :  [[-0.43648218  1.2066586  -0.00689375  0.01024777  0.12233535  0.00830254]]\n",
      "학습 횟수 :  947 theta값 :  [[-0.43649315  1.2070143  -0.00689294  0.00985704  0.12217812  0.00830632]]\n",
      "학습 횟수 :  948 theta값 :  [[-0.4365038   1.20736995 -0.00689215  0.00946708  0.12202121  0.00831009]]\n",
      "학습 횟수 :  949 theta값 :  [[-0.4365141   1.20772557 -0.00689139  0.00907791  0.12186461  0.00831386]]\n",
      "학습 횟수 :  950 theta값 :  [[-0.43652408  1.20808115 -0.00689066  0.00868951  0.12170833  0.00831762]]\n",
      "학습 횟수 :  951 theta값 :  [[-0.43653372  1.20843669 -0.00688996  0.00830189  0.12155236  0.00832137]]\n",
      "학습 횟수 :  952 theta값 :  [[-0.43654304  1.20879219 -0.00688928  0.00791504  0.1213967   0.00832511]]\n",
      "학습 횟수 :  953 theta값 :  [[-0.43655202  1.20914765 -0.00688864  0.00752895  0.12124135  0.00832885]]\n",
      "학습 횟수 :  954 theta값 :  [[-0.43656068  1.20950308 -0.00688802  0.00714364  0.12108631  0.00833258]]\n",
      "학습 횟수 :  955 theta값 :  [[-0.43656902  1.20985847 -0.00688743  0.00675908  0.12093158  0.00833631]]\n",
      "학습 횟수 :  956 theta값 :  [[-0.43657704  1.21021381 -0.00688687  0.00637529  0.12077716  0.00834003]]\n",
      "학습 횟수 :  957 theta값 :  [[-0.43658473  1.21056912 -0.00688633  0.00599227  0.12062305  0.00834374]]\n",
      "학습 횟수 :  958 theta값 :  [[-0.43659211  1.21092439 -0.00688583  0.00560999  0.12046925  0.00834744]]\n",
      "학습 횟수 :  959 theta값 :  [[-0.43659916  1.21127962 -0.00688535  0.00522848  0.12031574  0.00835113]]\n",
      "학습 횟수 :  960 theta값 :  [[-0.43660591  1.21163481 -0.00688489  0.00484772  0.12016255  0.00835482]]\n",
      "학습 횟수 :  961 theta값 :  [[-0.43661233  1.21198996 -0.00688447  0.00446771  0.12000966  0.00835851]]\n",
      "학습 횟수 :  962 theta값 :  [[-0.43661845  1.21234507 -0.00688407  0.00408845  0.11985707  0.00836218]]\n",
      "학습 횟수 :  963 theta값 :  [[-0.43662426  1.21270014 -0.0068837   0.00370993  0.11970478  0.00836585]]\n",
      "학습 횟수 :  964 theta값 :  [[-0.43662975  1.21305517 -0.00688335  0.00333217  0.11955279  0.00836951]]\n",
      "학습 횟수 :  965 theta값 :  [[-0.43663494  1.21341015 -0.00688303  0.00295514  0.1194011   0.00837317]]\n",
      "학습 횟수 :  966 theta값 :  [[-0.43663983  1.2137651  -0.00688274  0.00257886  0.11924972  0.00837681]]\n",
      "학습 횟수 :  967 theta값 :  [[-0.43664441  1.21412    -0.00688247  0.00220331  0.11909862  0.00838046]]\n",
      "학습 횟수 :  968 theta값 :  [[-0.43664869  1.21447487 -0.00688223  0.00182851  0.11894783  0.00838409]]\n",
      "학습 횟수 :  969 theta값 :  [[-0.43665266  1.21482969 -0.00688202  0.00145443  0.11879733  0.00838772]]\n",
      "학습 횟수 :  970 theta값 :  [[-4.36656342e-01  1.21518447e+00 -6.88183199e-03  1.08109495e-03\n",
      "   1.18647131e-01  8.39133690e-03]]\n",
      "학습 횟수 :  971 theta값 :  [[-4.36659723e-01  1.21553920e+00 -6.88166964e-03  7.08485705e-04\n",
      "   1.18497223e-01  8.39495052e-03]]\n",
      "학습 횟수 :  972 theta값 :  [[-4.36662808e-01  1.21589390e+00 -6.88153291e-03  3.36605026e-04\n",
      "   1.18347608e-01  8.39855735e-03]]\n",
      "학습 횟수 :  973 theta값 :  [[-4.36665600e-01  1.21624855e+00 -6.88142167e-03 -3.45491516e-05\n",
      "   1.18198285e-01  8.40215738e-03]]\n",
      "학습 횟수 :  974 theta값 :  [[-4.36668098e-01  1.21660316e+00 -6.88133579e-03 -4.04978885e-04\n",
      "   1.18049254e-01  8.40575064e-03]]\n",
      "학습 횟수 :  975 theta값 :  [[-4.36670305e-01  1.21695773e+00 -6.88127516e-03 -7.74686226e-04\n",
      "   1.17900514e-01  8.40933714e-03]]\n",
      "학습 횟수 :  976 theta값 :  [[-4.36672223e-01  1.21731226e+00 -6.88123964e-03 -1.14367322e-03\n",
      "   1.17752063e-01  8.41291689e-03]]\n",
      "학습 횟수 :  977 theta값 :  [[-0.43667385  1.21766674 -0.00688123 -0.00151194  0.1176039   0.00841649]]\n",
      "학습 횟수 :  978 theta값 :  [[-0.4366752   1.21802118 -0.00688124 -0.00187949  0.11745603  0.00842006]]\n",
      "학습 횟수 :  979 theta값 :  [[-0.43667626  1.21837557 -0.00688128 -0.00224633  0.11730844  0.00842362]]\n",
      "학습 횟수 :  980 theta값 :  [[-0.43667703  1.21872992 -0.00688135 -0.00261246  0.11716114  0.00842717]]\n",
      "학습 횟수 :  981 theta값 :  [[-0.43667753  1.21908423 -0.00688143 -0.00297787  0.11701412  0.00843071]]\n",
      "학습 횟수 :  982 theta값 :  [[-0.43667774  1.21943849 -0.00688155 -0.00334258  0.11686739  0.00843425]]\n",
      "학습 횟수 :  983 theta값 :  [[-0.43667768  1.21979271 -0.00688168 -0.00370658  0.11672094  0.00843779]]\n",
      "학습 횟수 :  984 theta값 :  [[-0.43667733  1.22014689 -0.00688184 -0.00406988  0.11657478  0.00844131]]\n",
      "학습 횟수 :  985 theta값 :  [[-0.43667672  1.22050102 -0.00688203 -0.00443247  0.11642889  0.00844483]]\n",
      "학습 횟수 :  986 theta값 :  [[-0.43667583  1.2208551  -0.00688224 -0.00479437  0.11628329  0.00844835]]\n",
      "학습 횟수 :  987 theta값 :  [[-0.43667466  1.22120914 -0.00688247 -0.00515557  0.11613796  0.00845185]]\n",
      "학습 횟수 :  988 theta값 :  [[-0.43667323  1.22156314 -0.00688273 -0.00551607  0.11599292  0.00845535]]\n",
      "학습 횟수 :  989 theta값 :  [[-0.43667152  1.22191709 -0.00688301 -0.00587587  0.11584815  0.00845885]]\n",
      "학습 횟수 :  990 theta값 :  [[-0.43666955  1.22227099 -0.00688331 -0.00623498  0.11570366  0.00846233]]\n",
      "학습 횟수 :  991 theta값 :  [[-0.43666731  1.22262485 -0.00688364 -0.00659341  0.11555945  0.00846581]]\n",
      "학습 횟수 :  992 theta값 :  [[-0.43666481  1.22297866 -0.00688399 -0.00695114  0.11541552  0.00846929]]\n",
      "학습 횟수 :  993 theta값 :  [[-0.43666204  1.22333243 -0.00688436 -0.00730819  0.11527185  0.00847275]]\n",
      "학습 횟수 :  994 theta값 :  [[-0.43665901  1.22368615 -0.00688476 -0.00766455  0.11512846  0.00847621]]\n",
      "학습 횟수 :  995 theta값 :  [[-0.43665572  1.22403982 -0.00688517 -0.00802023  0.11498535  0.00847967]]\n",
      "학습 횟수 :  996 theta값 :  [[-0.43665217  1.22439345 -0.00688561 -0.00837523  0.11484251  0.00848311]]\n",
      "학습 횟수 :  997 theta값 :  [[-0.43664837  1.22474703 -0.00688608 -0.00872955  0.11469993  0.00848655]]\n",
      "학습 횟수 :  998 theta값 :  [[-0.4366443   1.22510056 -0.00688657 -0.00908319  0.11455763  0.00848999]]\n",
      "학습 횟수 :  999 theta값 :  [[-0.43663999  1.22545405 -0.00688707 -0.00943616  0.1144156   0.00849342]]\n",
      "학습 횟수 :  1000 theta값 :  [[-0.43663541  1.22580749 -0.0068876  -0.00978846  0.11427384  0.00849684]]\n"
     ]
    }
   ],
   "source": [
    "train_num = 1000  # 학습 횟수\n",
    "a=0.00001  # 학습률\n",
    "z = 0\n",
    "\n",
    "for i in range(train_num):  # 학습 횟수 만큼 반복\n",
    "    for j in range(len(X_train)):  # 데이터 개수 만큼 반복\n",
    "        z = np.dot(X_train.loc[j],np.transpose(theta))\n",
    "        theta += np.array(a*(Y_train.loc[j] - sigmoid(z)) * X_train.loc[j])\n",
    "    print('학습 횟수 : ',i+1,'theta값 : ',theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  78.73134328358209\n"
     ]
    }
   ],
   "source": [
    "z = 0\n",
    "cnt = 0\n",
    "for i in range(len(X_test)):  # 데이터 개수 만큼 반복\n",
    "    z = np.dot(theta,X_test.loc[i])\n",
    "    if(sigmoid(z) >=0.5 and Y_test[i] == 1):\n",
    "        cnt+=1\n",
    "    elif(sigmoid(z) < 0.5 and Y_test[i] == 0):\n",
    "        cnt+=1\n",
    "accuracy = (cnt / len(X_test)) * 100\n",
    "print('정확도: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
